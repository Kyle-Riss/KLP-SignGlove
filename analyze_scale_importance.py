#!/usr/bin/env python3
"""
Scale-Aware GRU ìŠ¤ì¼€ì¼ ì¤‘ìš”ë„ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ê° CNN ìŠ¤ì¼€ì¼(k=3,5,7)ì˜ ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
"""
import sys
import os.path as op
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')

# Add project root to path
path = op.dirname(op.realpath(__file__))
sys.path.append(path)

from src.models.MSCSGRUModels_ScaleAware import MSCSGRU_ScaleAware, MSCSGRU_ScaleHard
from src.misc.DynamicDataModule import DynamicDataModule

def load_best_model(model_class, checkpoint_dir="lightning_logs"):
    """ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
    import glob
    
    # Find latest version directory
    version_dirs = glob.glob(f"{checkpoint_dir}/version_*")
    if not version_dirs:
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_dir}")
        return None
    
    latest_version = max(version_dirs, key=lambda x: int(x.split('_')[-1]))
    checkpoint_files = glob.glob(f"{latest_version}/checkpoints/*.ckpt")
    
    if not checkpoint_files:
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {latest_version}/checkpoints/")
        return None
    
    # Load best checkpoint
    best_checkpoint = checkpoint_files[0]
    print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {best_checkpoint}")
    
    model = model_class.load_from_checkpoint(
        best_checkpoint,
        learning_rate=0.001,
        input_size=8,
        hidden_size=64,
        classes=24
    )
    model.eval()
    return model

def analyze_scale_weights(model):
    """ìŠ¤ì¼€ì¼ë³„ ê°€ì¤‘ì¹˜ ë¶„ì„"""
    print("\n" + "="*80)
    print("ğŸ“Š ìŠ¤ì¼€ì¼ë³„ ê°€ì¤‘ì¹˜ ë¶„ì„")
    print("="*80)
    
    # GRU1ì˜ ì²« ë²ˆì§¸ ì…€ ë¶„ì„
    gru1_cell = model.gru1.cells[0]
    
    # Update gate weights
    W_z3_norm = torch.norm(gru1_cell.W_z3.weight).item()
    W_z5_norm = torch.norm(gru1_cell.W_z5.weight).item()
    W_z7_norm = torch.norm(gru1_cell.W_z7.weight).item()
    
    total_z = W_z3_norm + W_z5_norm + W_z7_norm
    
    print("\n1ï¸âƒ£  Update Gate (z_t) ê°€ì¤‘ì¹˜ í¬ê¸°:")
    print(f"  - W_z3 (k=3): {W_z3_norm:.4f} ({W_z3_norm/total_z*100:.1f}%)")
    print(f"  - W_z5 (k=5): {W_z5_norm:.4f} ({W_z5_norm/total_z*100:.1f}%)")
    print(f"  - W_z7 (k=7): {W_z7_norm:.4f} ({W_z7_norm/total_z*100:.1f}%)")
    
    # Reset gate weights
    W_r3_norm = torch.norm(gru1_cell.W_r3.weight).item()
    W_r5_norm = torch.norm(gru1_cell.W_r5.weight).item()
    W_r7_norm = torch.norm(gru1_cell.W_r7.weight).item()
    
    total_r = W_r3_norm + W_r5_norm + W_r7_norm
    
    print("\n2ï¸âƒ£  Reset Gate (r_t) ê°€ì¤‘ì¹˜ í¬ê¸°:")
    print(f"  - W_r3 (k=3): {W_r3_norm:.4f} ({W_r3_norm/total_r*100:.1f}%)")
    print(f"  - W_r5 (k=5): {W_r5_norm:.4f} ({W_r5_norm/total_r*100:.1f}%)")
    print(f"  - W_r7 (k=7): {W_r7_norm:.4f} ({W_r7_norm/total_r*100:.1f}%)")
    
    # Hidden gate weights
    W_h3_norm = torch.norm(gru1_cell.W_h3.weight).item()
    W_h5_norm = torch.norm(gru1_cell.W_h5.weight).item()
    W_h7_norm = torch.norm(gru1_cell.W_h7.weight).item()
    
    total_h = W_h3_norm + W_h5_norm + W_h7_norm
    
    print("\n3ï¸âƒ£  Hidden Gate (hÌƒ_t) ê°€ì¤‘ì¹˜ í¬ê¸°:")
    print(f"  - W_h3 (k=3): {W_h3_norm:.4f} ({W_h3_norm/total_h*100:.1f}%)")
    print(f"  - W_h5 (k=5): {W_h5_norm:.4f} ({W_h5_norm/total_h*100:.1f}%)")
    print(f"  - W_h7 (k=7): {W_h7_norm:.4f} ({W_h7_norm/total_h*100:.1f}%)")
    
    # Overall importance
    avg_3 = (W_z3_norm/total_z + W_r3_norm/total_r + W_h3_norm/total_h) / 3
    avg_5 = (W_z5_norm/total_z + W_r5_norm/total_r + W_h5_norm/total_h) / 3
    avg_7 = (W_z7_norm/total_z + W_r7_norm/total_r + W_h7_norm/total_h) / 3
    
    print("\nğŸ¯ ì „ì²´ í‰ê·  ì¤‘ìš”ë„:")
    print(f"  - Scale k=3 (ì§§ì€ íŒ¨í„´): {avg_3*100:.1f}%")
    print(f"  - Scale k=5 (ì¤‘ê°„ íŒ¨í„´): {avg_5*100:.1f}%")
    print(f"  - Scale k=7 (ê¸´ íŒ¨í„´): {avg_7*100:.1f}%")
    
    # Determine most important scale
    scales = {'k=3': avg_3, 'k=5': avg_5, 'k=7': avg_7}
    most_important = max(scales, key=scales.get)
    
    print(f"\nâœ¨ ê°€ì¥ ì¤‘ìš”í•œ ìŠ¤ì¼€ì¼: {most_important} ({scales[most_important]*100:.1f}%)")
    
    return {
        'update_gate': [W_z3_norm/total_z, W_z5_norm/total_z, W_z7_norm/total_z],
        'reset_gate': [W_r3_norm/total_r, W_r5_norm/total_r, W_r7_norm/total_r],
        'hidden_gate': [W_h3_norm/total_h, W_h5_norm/total_h, W_h7_norm/total_h],
        'overall': [avg_3, avg_5, avg_7]
    }

def visualize_scale_importance(importance_data):
    """ìŠ¤ì¼€ì¼ ì¤‘ìš”ë„ ì‹œê°í™”"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Scale Importance Analysis in Scale-Aware GRU', fontsize=16, fontweight='bold')
    
    scales = ['k=3\n(Short)', 'k=5\n(Medium)', 'k=7\n(Long)']
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    
    # 1. Update Gate
    ax = axes[0, 0]
    bars = ax.bar(scales, importance_data['update_gate'], color=colors, alpha=0.7, edgecolor='black', linewidth=2)
    ax.set_ylabel('Relative Importance', fontsize=12)
    ax.set_title('Update Gate (z_t)', fontsize=13, fontweight='bold')
    ax.set_ylim(0, 0.6)
    ax.grid(True, alpha=0.3, axis='y')
    
    for bar, val in zip(bars, importance_data['update_gate']):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{val*100:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    # 2. Reset Gate
    ax = axes[0, 1]
    bars = ax.bar(scales, importance_data['reset_gate'], color=colors, alpha=0.7, edgecolor='black', linewidth=2)
    ax.set_ylabel('Relative Importance', fontsize=12)
    ax.set_title('Reset Gate (r_t)', fontsize=13, fontweight='bold')
    ax.set_ylim(0, 0.6)
    ax.grid(True, alpha=0.3, axis='y')
    
    for bar, val in zip(bars, importance_data['reset_gate']):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{val*100:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    # 3. Hidden Gate
    ax = axes[1, 0]
    bars = ax.bar(scales, importance_data['hidden_gate'], color=colors, alpha=0.7, edgecolor='black', linewidth=2)
    ax.set_ylabel('Relative Importance', fontsize=12)
    ax.set_title('Hidden Gate (hÌƒ_t)', fontsize=13, fontweight='bold')
    ax.set_ylim(0, 0.6)
    ax.grid(True, alpha=0.3, axis='y')
    
    for bar, val in zip(bars, importance_data['hidden_gate']):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{val*100:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    # 4. Overall Average
    ax = axes[1, 1]
    bars = ax.bar(scales, importance_data['overall'], color=colors, alpha=0.7, edgecolor='black', linewidth=2)
    ax.set_ylabel('Average Importance', fontsize=12)
    ax.set_title('Overall Scale Importance', fontsize=13, fontweight='bold')
    ax.set_ylim(0, 0.6)
    ax.grid(True, alpha=0.3, axis='y')
    
    for bar, val in zip(bars, importance_data['overall']):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{val*100:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('scale_importance_analysis.png', dpi=300, bbox_inches='tight')
    print("\nâœ… ìŠ¤ì¼€ì¼ ì¤‘ìš”ë„ í”Œë¡¯ ì €ì¥: scale_importance_analysis.png")

def test_scale_ablation(model, datamodule):
    """ìŠ¤ì¼€ì¼ë³„ Ablation Study"""
    print("\n" + "="*80)
    print("ğŸ§ª ìŠ¤ì¼€ì¼ Ablation Study")
    print("="*80)
    print("\nê° ìŠ¤ì¼€ì¼ì„ ì œê±°í–ˆì„ ë•Œì˜ ì„±ëŠ¥ ë³€í™”ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤...")
    
    model.eval()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    test_loader = datamodule.test_dataloader()
    
    def evaluate_with_ablation(ablate_scale=None):
        """íŠ¹ì • ìŠ¤ì¼€ì¼ì„ ì œê±°í•˜ê³  í‰ê°€"""
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in test_loader:
                x, y, padding = batch
                x = x.to(device)
                y = y.to(device)
                padding = padding.to(device)
                
                # Forward pass with ablation
                if ablate_scale:
                    # Temporarily zero out specific scale weights
                    gru1_cell = model.gru1.cells[0]
                    
                    if ablate_scale == 3:
                        original_z3 = gru1_cell.W_z3.weight.data.clone()
                        original_r3 = gru1_cell.W_r3.weight.data.clone()
                        original_h3 = gru1_cell.W_h3.weight.data.clone()
                        gru1_cell.W_z3.weight.data.zero_()
                        gru1_cell.W_r3.weight.data.zero_()
                        gru1_cell.W_h3.weight.data.zero_()
                    elif ablate_scale == 5:
                        original_z5 = gru1_cell.W_z5.weight.data.clone()
                        original_r5 = gru1_cell.W_r5.weight.data.clone()
                        original_h5 = gru1_cell.W_h5.weight.data.clone()
                        gru1_cell.W_z5.weight.data.zero_()
                        gru1_cell.W_r5.weight.data.zero_()
                        gru1_cell.W_h5.weight.data.zero_()
                    elif ablate_scale == 7:
                        original_z7 = gru1_cell.W_z7.weight.data.clone()
                        original_r7 = gru1_cell.W_r7.weight.data.clone()
                        original_h7 = gru1_cell.W_h7.weight.data.clone()
                        gru1_cell.W_z7.weight.data.zero_()
                        gru1_cell.W_r7.weight.data.zero_()
                        gru1_cell.W_h7.weight.data.zero_()
                
                logits, _ = model(x, padding, y)
                _, predicted = torch.max(logits, 1)
                
                total += y.size(0)
                correct += (predicted == y).sum().item()
                
                # Restore weights
                if ablate_scale:
                    if ablate_scale == 3:
                        gru1_cell.W_z3.weight.data = original_z3
                        gru1_cell.W_r3.weight.data = original_r3
                        gru1_cell.W_h3.weight.data = original_h3
                    elif ablate_scale == 5:
                        gru1_cell.W_z5.weight.data = original_z5
                        gru1_cell.W_r5.weight.data = original_r5
                        gru1_cell.W_h5.weight.data = original_h5
                    elif ablate_scale == 7:
                        gru1_cell.W_z7.weight.data = original_z7
                        gru1_cell.W_r7.weight.data = original_r7
                        gru1_cell.W_h7.weight.data = original_h7
        
        return correct / total
    
    # Full model
    print("\nğŸ“Š í‰ê°€ ì¤‘...")
    full_acc = evaluate_with_ablation(ablate_scale=None)
    print(f"  âœ… ì „ì²´ ëª¨ë¸: {full_acc*100:.2f}%")
    
    # Ablate k=3
    acc_without_3 = evaluate_with_ablation(ablate_scale=3)
    drop_3 = (full_acc - acc_without_3) * 100
    print(f"  âŒ k=3 ì œê±°: {acc_without_3*100:.2f}% (ì„±ëŠ¥ í•˜ë½: {drop_3:.2f}%)")
    
    # Ablate k=5
    acc_without_5 = evaluate_with_ablation(ablate_scale=5)
    drop_5 = (full_acc - acc_without_5) * 100
    print(f"  âŒ k=5 ì œê±°: {acc_without_5*100:.2f}% (ì„±ëŠ¥ í•˜ë½: {drop_5:.2f}%)")
    
    # Ablate k=7
    acc_without_7 = evaluate_with_ablation(ablate_scale=7)
    drop_7 = (full_acc - acc_without_7) * 100
    print(f"  âŒ k=7 ì œê±°: {acc_without_7*100:.2f}% (ì„±ëŠ¥ í•˜ë½: {drop_7:.2f}%)")
    
    print("\nğŸ’¡ ê²°ë¡ :")
    drops = {'k=3': drop_3, 'k=5': drop_5, 'k=7': drop_7}
    most_critical = max(drops, key=drops.get)
    print(f"  ê°€ì¥ ì¤‘ìš”í•œ ìŠ¤ì¼€ì¼: {most_critical} (ì œê±° ì‹œ {drops[most_critical]:.2f}% í•˜ë½)")
    
    return {
        'full': full_acc,
        'without_3': acc_without_3,
        'without_5': acc_without_5,
        'without_7': acc_without_7,
        'drops': [drop_3, drop_5, drop_7]
    }

def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  Scale-Aware GRU ìŠ¤ì¼€ì¼ ì¤‘ìš”ë„ ë¶„ì„                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Load model
    print("\nğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = load_best_model(MSCSGRU_ScaleAware)
    
    if model is None:
        print("\nâŒ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return
    
    # Analyze weights
    importance_data = analyze_scale_weights(model)
    
    # Visualize
    print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
    visualize_scale_importance(importance_data)
    
    # Ablation study
    print("\nğŸ“¦ ë°ì´í„° ë¡œë”© ì¤‘...")
    datamodule = DynamicDataModule(
        time_steps=87,
        batch_size=32,
        kfold=0,
        splits=5,
        seed=42
    )
    datamodule.setup()
    
    ablation_results = test_scale_ablation(model, datamodule)
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         ë¶„ì„ ì™„ë£Œ!                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ìƒì„±ëœ íŒŒì¼:
  ğŸ“Š scale_importance_analysis.png - ìŠ¤ì¼€ì¼ ì¤‘ìš”ë„ ì‹œê°í™”

ì£¼ìš” ë°œê²¬ì‚¬í•­:
  - ê°€ì¤‘ì¹˜ ë¶„ì„ì„ í†µí•´ ê° ìŠ¤ì¼€ì¼ì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ í™•ì¸
  - Ablation studyë¥¼ í†µí•´ ê° ìŠ¤ì¼€ì¼ì˜ ì‹¤ì œ ê¸°ì—¬ë„ ì¸¡ì •
  - ì´ ì •ë³´ëŠ” ëª¨ë¸ ìµœì í™” ë° í•´ì„ì— í™œìš© ê°€ëŠ¥
    """)

if __name__ == "__main__":
    main()

