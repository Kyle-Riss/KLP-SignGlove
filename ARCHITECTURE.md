# MS-CSGRU Model Architecture

## Overview

**MS-CSGRU** = **Multi-Scale CNN + Stacked GRU**

A hybrid deep learning architecture that combines multi-scale convolutional neural networks for feature extraction with stacked GRU layers for temporal sequence modeling, specifically designed for Korean Sign Language recognition.

---

## Architecture Diagram

![MS-CSGRU Architecture](visualizations/MSCSGRU_architecture_flowchart.png)

![Dimension Flow](visualizations/MSCSGRU_dimension_flow.png)

---

## Complete Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Input Layer                                     â”‚
â”‚                   Sensor Data: [batch, 87, 8]                           â”‚
â”‚                   87 timesteps Ã— 8 channels                             â”‚
â”‚                   (flex1-5 + pitch, roll, yaw)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Multi-Scale CNN Encoder                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Multi-Head Attention (Parallel Processing)           â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚  Tower 1     â”‚  â”‚  Tower 2     â”‚  â”‚  Tower 3     â”‚          â”‚  â”‚
â”‚  â”‚  â”‚  Conv1D(k=3) â”‚  â”‚  Conv1D(k=5) â”‚  â”‚  Conv1D(k=7) â”‚          â”‚  â”‚
â”‚  â”‚  â”‚  in: 8       â”‚  â”‚  in: 8       â”‚  â”‚  in: 8       â”‚          â”‚  â”‚
â”‚  â”‚  â”‚  out: 32     â”‚  â”‚  out: 32     â”‚  â”‚  out: 32     â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚         â”‚                 â”‚                 â”‚                   â”‚  â”‚
â”‚  â”‚         â”‚   BatchNorm     â”‚   BatchNorm     â”‚   BatchNorm       â”‚  â”‚
â”‚  â”‚         â”‚       â†“         â”‚       â†“         â”‚       â†“           â”‚  â”‚
â”‚  â”‚         â”‚     ReLU        â”‚     ReLU        â”‚     ReLU          â”‚  â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚  â”‚
â”‚  â”‚                           â†“                                      â”‚  â”‚
â”‚  â”‚                  Concatenate (96 channels)                       â”‚  â”‚
â”‚  â”‚                           â†“                                      â”‚  â”‚
â”‚  â”‚              BatchNorm â†’ ReLU â†’ MaxPool(2) â†’ Dropout(0.3)       â”‚  â”‚
â”‚  â”‚                           â†“                                      â”‚  â”‚
â”‚  â”‚                  Hidden State H [43, 96]                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Stacked GRU Layers                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    GRU Layer 1 (First Layer)                      â”‚  â”‚
â”‚  â”‚            GRU Cell (input: 96, hidden: 64)                       â”‚  â”‚
â”‚  â”‚                         â†“                                         â”‚  â”‚
â”‚  â”‚                    Dropout(0.3)                                   â”‚  â”‚
â”‚  â”‚                         â†“                                         â”‚  â”‚
â”‚  â”‚                  Output: [43, 64]                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    GRU Layer 2 (Second Layer)                     â”‚  â”‚
â”‚  â”‚            GRU Cell (input: 64, hidden: 64)                       â”‚  â”‚
â”‚  â”‚                         â†“                                         â”‚  â”‚
â”‚  â”‚                  Output: [43, 64]                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Padding-Aware Feature Extraction â­                    â”‚
â”‚                                                                          â”‚
â”‚   if x_padding is not None:                                             â”‚
â”‚       valid_lengths = (x_padding == 0).sum(dim=1) - 1                   â”‚
â”‚       final_features = gru_out[batch_idx, valid_lengths]                â”‚
â”‚   else:                                                                  â”‚
â”‚       final_features = gru_out[:, -1, :]                                â”‚
â”‚                                                                          â”‚
â”‚                      Output: [batch, 64]                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Classifier                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Linear(64 â†’ 128)                               â”‚  â”‚
â”‚  â”‚                         â†“                                         â”‚  â”‚
â”‚  â”‚                       ReLU                                        â”‚  â”‚
â”‚  â”‚                         â†“                                         â”‚  â”‚
â”‚  â”‚                    Dropout(0.3)                                   â”‚  â”‚
â”‚  â”‚                         â†“                                         â”‚  â”‚
â”‚  â”‚                    Linear(128 â†’ 24)                               â”‚  â”‚
â”‚  â”‚                         â†“                                         â”‚  â”‚
â”‚  â”‚                  Logits: [batch, 24]                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Output                                         â”‚
â”‚                    24 Classes (14 consonants + 10 vowels)               â”‚
â”‚                    Softmax Probabilities                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Layer-by-Layer Breakdown

### 1. Input Layer

**Shape**: `(batch_size, 87, 8)`

- **87 timesteps**: ~2.7 seconds of sign gesture (32.1 Hz sampling)
- **8 channels**:
  - `flex1-5`: 5 finger bend sensors
  - `pitch, roll, yaw`: Wrist rotation angles (IMU sensor)

---

### 2. Multi-Scale CNN Encoder

#### Purpose
Extract features at multiple temporal scales simultaneously.

#### Architecture

**Three Parallel Towers:**

```python
# Tower 1: Short-term patterns (fine movements)
Conv1D(in=8, out=32, kernel=3, padding=1)
â†’ BatchNorm1d(32) â†’ ReLU()

# Tower 2: Medium-term patterns (general movements)
Conv1D(in=8, out=32, kernel=5, padding=2)
â†’ BatchNorm1d(32) â†’ ReLU()

# Tower 3: Long-term patterns (overall gesture)
Conv1D(in=8, out=32, kernel=7, padding=3)
â†’ BatchNorm1d(32) â†’ ReLU()
```

**Concatenation:**
```python
conv_out = torch.cat([tower1, tower2, tower3], dim=1)
# Output: (batch, 96, 87)
```

**Post-processing:**
```python
BatchNorm1d(96) â†’ ReLU() â†’ MaxPool1d(2, 2) â†’ Dropout(0.3)
# Output: (batch, 96, 43) - sequence length halved
```

#### Why Multi-Scale?

- **kernel=3**: Short time window (0.09s) - captures rapid movements
- **kernel=5**: Medium time window (0.16s) - captures general patterns
- **kernel=7**: Long time window (0.22s) - captures overall gesture flow

â†’ **Learning 3 scales simultaneously** provides richer feature representation!

---

### 3. Stacked GRU Layers

```python
# GRU Layer 1
gru1 = GRU(input_size=96, hidden_size=64, num_layers=1)
gru1_out, _ = gru1(conv_out)
# Output: (batch, 43, 64)

gru1_out = Dropout(0.3)(gru1_out)

# GRU Layer 2
gru2 = GRU(input_size=64, hidden_size=64, num_layers=1)
gru2_out, _ = gru2(gru1_out)
# Output: (batch, 43, 64)
```

#### Why Stacked GRU?

- **Layer 1**: Learns low-level temporal patterns (sensor value changes)
- **Layer 2**: Learns high-level temporal patterns (gesture semantics)

â†’ **Hierarchical temporal representation** for better sequence understanding!

---

### 4. Padding-Aware Feature Extraction â­

**Key Innovation!**

```python
if x_padding is not None:
    # x_padding: (batch, 87) - 1.0 = padding, 0.0 = real data
    
    # Calculate actual data length for each sample
    valid_lengths = (x_padding == 0).sum(dim=1) - 1  # 0-indexed
    # Example: [79, 74, 84, 86] - varies per sample!
    
    # Adjust for MaxPool (87 â†’ 43)
    valid_lengths = valid_lengths.clamp(min=0, max=gru2_out.size(1)-1)
    
    # Extract features from last valid timestep of each sample
    batch_size = gru2_out.size(0)
    final_features = gru2_out[torch.arange(batch_size), valid_lengths]
else:
    # Fallback: use last timestep
    final_features = gru2_out[:, -1, :]

# Output: (batch, 64)
```

#### Why Is This Important?

**Old Approach (âŒ):**
```
Sample 1 (80 real, 7 padding): Uses timestep 43
  â†’ Padding went through GRU 3-4 times (contaminated!)

Sample 2 (75 real, 12 padding): Uses timestep 43
  â†’ Padding went through GRU 6 times (more contaminated!)
```

**Improved Approach (âœ…):**
```
Sample 1 (80 real): Uses timestep 39 (80/2 â‰ˆ 40)
  â†’ Pure features from real data only!

Sample 2 (75 real): Uses timestep 37 (75/2 â‰ˆ 37)
  â†’ Pure features from real data only!
```

---

### 5. Classifier

```python
output_layers = Sequential(
    Linear(64, 128),      # Feature expansion
    ReLU(),               # Non-linear activation
    Dropout(0.3),         # Prevent overfitting
    Linear(128, 24)       # 24 class logits
)

logits = output_layers(final_features)
# Output: (batch, 24)

# Loss calculation
loss = CrossEntropyLoss(logits, y_targets)
```

---

## Dimension Flow Summary

```
Input:         (batch, 87, 8)
   â†“ transpose
CNN Input:     (batch, 8, 87)
   â†“ 3 towers + concat
CNN Mid:       (batch, 96, 87)
   â†“ MaxPool(2)
CNN Output:    (batch, 96, 43)
   â†“ transpose
GRU Input:     (batch, 43, 96)
   â†“ GRU1
GRU1 Output:   (batch, 43, 64)
   â†“ GRU2
GRU2 Output:   (batch, 43, 64)
   â†“ Padding-aware
Features:      (batch, 64)
   â†“ Dense
Logits:        (batch, 24)
```

---

## Model Parameters

```python
MSCSGRU(
    learning_rate=1e-3,
    input_size=8,          # Number of sensor channels
    hidden_size=64,        # GRU hidden size
    classes=24,            # 14 consonants + 10 vowels
    cnn_filters=32,        # Filters per tower
    gru_layers=2,          # Number of GRU layers
    dropout=0.3            # Dropout rate
)
```

**Total Parameters**: ~150K (lightweight model)

---

## Why This Architecture Works

### 1. Multi-Scale CNN Benefits

```
Sign gesture = combination of fast + slow movements

Example: "ã„±" sign
- Fast movement (kernel=3): Finger bending (0.1s)
- Medium movement (kernel=5): Wrist rotation (0.3s)
- Slow movement (kernel=7): Overall posture maintenance (0.5s)

â†’ Learning all 3 scales = more accurate recognition!
```

### 2. Stacked GRU Benefits

```
Layer 1 GRU: "Finger bent"
Layer 2 GRU: "This is 'ã„±' gesture"

â†’ Hierarchical abstraction = more meaningful representation!
```

### 3. Padding-Aware Benefits

```
Old: All samples use 87th timestep
  â†’ Samples with more padding perform worse

New: Each sample uses its actual last timestep
  â†’ Extract pure features only, better performance!
```

---

## Performance

| Model | Structure | Test Acc | Features |
|-------|-----------|----------|----------|
| **GRU** | Simple GRU | **99.31%** | Fast & stable |
| **CNNGRU** | Single CNN + GRU | 99.3% | Basic features |
| **MSCSGRU** | Multi-scale CNN + 2-layer GRU | 99.3% | **Rich features** |

**MSCSGRU Strengths:**
- Learns multiple temporal scale patterns
- Hierarchical temporal representation
- Better for complex gesture recognition

---

## Real-World Example

### Recognizing "ã„±" Sign

```
1. Input (87 timesteps, 8 channels)
   Timesteps 0-79: Real gesture data
   Timesteps 80-86: Padding (0.0)

2. Multi-Scale CNN
   Tower1 (kernel=3): Detects rapid finger bending
   Tower2 (kernel=5): Detects wrist rotation pattern
   Tower3 (kernel=7): Detects overall posture pattern
   â†’ Combine 3 features (96 channels)

3. Stacked GRU
   GRU1: Low-level temporal patterns
     "Timestep 10: Finger bending starts"
     "Timestep 30: Wrist rotation starts"
   GRU2: High-level temporal patterns
     "This sequence is typical 'ã„±' pattern"

4. Padding-Aware Feature Extraction
   Real length 79 â†’ After MaxPool ~39
   Extract features from timestep 39
   â†’ Pure 'ã„±' gesture features only!

5. Classifier
   64-dim features â†’ 128-dim expansion â†’ 24 class logits
   Softmax â†’ "ã„±" probability 99.87%
```

---

## Key Takeaways

1. **Multi-Scale CNN**: Parallel learning of various temporal scale patterns
2. **Stacked GRU**: Hierarchical temporal representation for complex sequences
3. **Padding-Aware**: Pure feature extraction using only real data
4. **Lightweight**: 150K parameters for real-time inference
5. **High Performance**: 99.3% accuracy on 24 classes

This architecture is a hybrid design optimized for sign language recognition, considering **time + space + scale** dimensions! ğŸš€

---

## Code Implementation

See `src/models/MSCSGRUModels.py` for the complete PyTorch implementation.

## Visualization

Run the visualization script to generate architecture diagrams:

```bash
python3 visualize_architecture.py
```

This will create:
- `visualizations/MSCSGRU_architecture_flowchart.png` - Full architecture diagram
- `visualizations/MSCSGRU_dimension_flow.png` - Dimension transformation flow

