"""
A-GRU ë…¸ì´ì¦ˆ ê²¬ê³ ì„± ë¶„ì„
Accuracy degradation under various noise levels
"""

import torch
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

from src.models.AGRUModels import AGRUModel
from src.models.GRUModels import StackedGRU, GRU
from src.models.MSCSGRUModels import MSCSGRU
from src.misc.DynamicDataModule import DynamicDataModule

# ì¶œë ¥ ë””ë ‰í† ë¦¬
OUTPUT_DIR = Path("visualizations/noise_robustness")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def add_gaussian_noise(x, noise_level):
    """
    ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
    
    Args:
        x: (batch, time, features) ì…ë ¥ ë°ì´í„°
        noise_level: ë…¸ì´ì¦ˆ ê°•ë„ (0.0 ~ 1.0)
    
    Returns:
        ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ ë°ì´í„°
    """
    noise = torch.randn_like(x) * noise_level
    return x + noise


def evaluate_with_noise(model, datamodule, noise_level=0.0):
    """
    íŠ¹ì • ë…¸ì´ì¦ˆ ë ˆë²¨ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    
    Args:
        model: í‰ê°€í•  ëª¨ë¸
        datamodule: ë°ì´í„° ëª¨ë“ˆ
        noise_level: ë…¸ì´ì¦ˆ ê°•ë„
    
    Returns:
        accuracy: ì •í™•ë„
    """
    datamodule.setup('test')
    test_loader = datamodule.test_dataloader()
    
    model.eval()
    device = torch.device('cpu')
    model = model.to(device)
    
    correct = 0
    total = 0
    
    with torch.no_grad():
        for batch in test_loader:
            x = batch['measurement'].to(device)
            y = batch['label'].to(device)
            
            # padding í‚¤ í™•ì¸ (LightningModel.pyì™€ ë™ì¼í•˜ê²Œ)
            x_padding = batch.get('measurement_padding', None)
            if x_padding is not None:
                x_padding = x_padding.to(device)
            else:
                x_padding = torch.zeros(x.size(0), x.size(1), device=device)
            
            # ë…¸ì´ì¦ˆ ì¶”ê°€
            if noise_level > 0:
                x = add_gaussian_noise(x, noise_level)
            
            # ì˜ˆì¸¡ (ëª¨ë“  LightningModelì€ ë™ì¼í•œ forward signature)
            # forward(x, x_padding, y) - label í•„ìš”
            logits, _ = model(x, x_padding, y)
            
            pred = torch.argmax(logits, dim=1)
            correct += (pred == y).sum().item()
            total += y.size(0)
    
    accuracy = correct / total if total > 0 else 0
    return accuracy


def analyze_noise_robustness(models, datamodule, noise_levels):
    """
    ì—¬ëŸ¬ ë…¸ì´ì¦ˆ ë ˆë²¨ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„
    
    Args:
        models: dict of models {name: model}
        datamodule: ë°ì´í„° ëª¨ë“ˆ
        noise_levels: list of noise levels
    
    Returns:
        results: dict of {model_name: [accuracies]}
    """
    results = {}
    
    print("\n" + "="*60)
    print("ğŸ“Š ë…¸ì´ì¦ˆ ê²¬ê³ ì„± ë¶„ì„")
    print("="*60)
    
    for name, model in models.items():
        print(f"\nğŸ” Analyzing {name}...")
        accuracies = []
        
        for noise_level in tqdm(noise_levels, desc=f"  {name}"):
            acc = evaluate_with_noise(model, datamodule, noise_level)
            accuracies.append(acc * 100)  # Convert to percentage
            
        results[name] = accuracies
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"  Clean (0.0): {accuracies[0]:.2f}%")
        print(f"  Noisy (0.1): {accuracies[-1]:.2f}%")
        print(f"  Degradation: {accuracies[0] - accuracies[-1]:.2f}%p")
    
    return results


def plot_noise_robustness(results, noise_levels):
    """ë…¸ì´ì¦ˆ ê²¬ê³ ì„± í”Œë¡¯"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Color palette
    colors = {'GRU': '#3498db', 'A-GRU': '#e74c3c', 'MS-CSGRU': '#2ecc71'}
    
    # 1. Accuracy vs Noise Level
    ax = axes[0]
    for name, accuracies in results.items():
        ax.plot(noise_levels, accuracies, marker='o', linewidth=2, 
                label=name, color=colors.get(name, 'gray'))
    
    ax.set_xlabel('Noise Level (Ïƒ)', fontsize=12, fontweight='bold')
    ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
    ax.set_title('Accuracy vs Noise Level', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 105)
    
    # 2. Accuracy Degradation
    ax = axes[1]
    
    model_names = list(results.keys())
    clean_accs = [results[name][0] for name in model_names]
    noisy_accs = [results[name][-1] for name in model_names]
    degradations = [clean_accs[i] - noisy_accs[i] for i in range(len(model_names))]
    
    x_pos = np.arange(len(model_names))
    bars = ax.bar(x_pos, degradations, color=[colors.get(name, 'gray') for name in model_names],
                  alpha=0.7, edgecolor='black')
    
    ax.set_xticks(x_pos)
    ax.set_xticklabels(model_names)
    ax.set_ylabel('Accuracy Degradation (%p)', fontsize=12, fontweight='bold')
    ax.set_title('Accuracy Degradation (Clean â†’ Noise 0.1)', fontsize=14, fontweight='bold')
    ax.grid(axis='y', alpha=0.3)
    
    # ê°’ í‘œì‹œ
    for bar, val in zip(bars, degradations):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.2f}%p',
                ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / "noise_robustness.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\nâœ… ë…¸ì´ì¦ˆ ê²¬ê³ ì„± í”Œë¡¯ ì €ì¥: {output_path}")
    plt.close()


def plot_noise_sensitivity_heatmap(results, noise_levels):
    """ë…¸ì´ì¦ˆ ë¯¼ê°ë„ íˆíŠ¸ë§µ"""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    model_names = list(results.keys())
    data = np.array([results[name] for name in model_names])
    
    # íˆíŠ¸ë§µ ìƒì„±
    sns.heatmap(data, annot=True, fmt='.1f', cmap='RdYlGn',
                xticklabels=[f'{level:.2f}' for level in noise_levels],
                yticklabels=model_names,
                cbar_kws={'label': 'Accuracy (%)'},
                vmin=0, vmax=100,
                ax=ax)
    
    ax.set_xlabel('Noise Level (Ïƒ)', fontsize=12, fontweight='bold')
    ax.set_ylabel('Model', fontsize=12, fontweight='bold')
    ax.set_title('Accuracy under Different Noise Levels', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / "noise_sensitivity_heatmap.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ë…¸ì´ì¦ˆ ë¯¼ê°ë„ íˆíŠ¸ë§µ ì €ì¥: {output_path}")
    plt.close()


def plot_relative_robustness(results, noise_levels):
    """ìƒëŒ€ì  ê²¬ê³ ì„± í”Œë¡¯ (GRU ê¸°ì¤€)"""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # GRUë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ì  ì„±ëŠ¥ ê³„ì‚°
    gru_accs = results['GRU']
    
    colors = {'A-GRU': '#e74c3c', 'MS-CSGRU': '#2ecc71'}
    
    for name, accuracies in results.items():
        if name == 'GRU':
            continue
        
        # ìƒëŒ€ì  ì„±ëŠ¥ (GRU ëŒ€ë¹„ ì°¨ì´)
        relative_perf = [acc - gru_acc for acc, gru_acc in zip(accuracies, gru_accs)]
        
        ax.plot(noise_levels, relative_perf, marker='o', linewidth=2,
                label=f'{name} vs GRU', color=colors.get(name, 'gray'))
    
    ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)
    ax.set_xlabel('Noise Level (Ïƒ)', fontsize=12, fontweight='bold')
    ax.set_ylabel('Accuracy Difference vs GRU (%p)', fontsize=12, fontweight='bold')
    ax.set_title('Relative Performance vs Baseline GRU', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / "relative_robustness.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ìƒëŒ€ì  ê²¬ê³ ì„± í”Œë¡¯ ì €ì¥: {output_path}")
    plt.close()


def print_summary_table(results, noise_levels):
    """ê²°ê³¼ ìš”ì•½ í…Œì´ë¸” ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“Š ë…¸ì´ì¦ˆ ê²¬ê³ ì„± ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("="*80)
    
    # í—¤ë”
    print(f"{'Model':<15} {'Clean (0.0)':<15} {'Noise (0.05)':<15} {'Noise (0.1)':<15} {'Degradation':<15}")
    print("-"*80)
    
    # ê° ëª¨ë¸
    for name, accuracies in results.items():
        clean = accuracies[0]
        noise_05 = accuracies[len(accuracies)//2] if len(accuracies) > 1 else accuracies[0]
        noise_10 = accuracies[-1]
        degradation = clean - noise_10
        
        print(f"{name:<15} {clean:>13.2f}% {noise_05:>13.2f}% {noise_10:>13.2f}% {degradation:>13.2f}%p")
    
    print("="*80)
    
    # ìµœê³  ê²¬ê³ ì„± ëª¨ë¸
    print("\n" + "="*80)
    print("ğŸ† ë…¸ì´ì¦ˆ ê²¬ê³ ì„± ìˆœìœ„")
    print("="*80)
    
    degradations = {name: accuracies[0] - accuracies[-1] 
                   for name, accuracies in results.items()}
    sorted_models = sorted(degradations.items(), key=lambda x: x[1])
    
    for rank, (name, deg) in enumerate(sorted_models, 1):
        symbol = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else "  "
        print(f"{symbol} {rank}. {name:<15}: {deg:.2f}%p degradation")
    
    print("="*80)
    
    # A-GRU ë¶„ì„
    if 'A-GRU' in results:
        print("\n" + "="*80)
        print("ğŸ”¬ A-GRU ê²¬ê³ ì„± ë¶„ì„")
        print("="*80)
        
        agru_deg = degradations['A-GRU']
        gru_deg = degradations.get('GRU', 0)
        
        improvement = gru_deg - agru_deg
        improvement_pct = (improvement / gru_deg * 100) if gru_deg > 0 else 0
        
        print(f"A-GRU degradation: {agru_deg:.2f}%p")
        print(f"GRU degradation: {gru_deg:.2f}%p")
        print(f"Improvement: {improvement:.2f}%p ({improvement_pct:+.1f}%)")
        
        if improvement > 0:
            print(f"\nâœ… A-GRUëŠ” GRUë³´ë‹¤ {improvement:.2f}%p ë” ê²¬ê³ í•©ë‹ˆë‹¤!")
        elif improvement < 0:
            print(f"\nâš ï¸ A-GRUëŠ” GRUë³´ë‹¤ {abs(improvement):.2f}%p ëœ ê²¬ê³ í•©ë‹ˆë‹¤.")
        else:
            print(f"\nâ– A-GRUì™€ GRUì˜ ê²¬ê³ ì„±ì€ ë¹„ìŠ·í•©ë‹ˆë‹¤.")
        
        print("="*80)


def load_trained_models():
    """í•™ìŠµëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
    models = {}
    
    # 1. GRU
    print("ğŸ“¦ Loading GRU...")
    try:
        # GRU ëª¨ë¸ì€ Linear + GRU êµ¬ì¡°ë¡œ ì €ì¥ë¨
        gru = GRU.load_from_checkpoint(
            "checkpoints/GRU_best.ckpt",
            learning_rate=0.001,
            input_size=8,
            hidden_size=64,
            classes=24,
            layers=2,
            dropout=0.3
        )
        models['GRU'] = gru
        print("   âœ… GRU loaded")
    except Exception as e:
        print(f"   âš ï¸ GRU not found, creating new: {e}")
        gru = GRU(
            learning_rate=0.001,
            input_size=8,
            hidden_size=64,
            classes=24,
            layers=2,
            dropout=0.3
        )
        models['GRU'] = gru
    
    # 2. A-GRU
    print("ğŸ“¦ Loading A-GRU...")
    try:
        agru = AGRUModel.load_from_checkpoint(
            "checkpoints/AGRU_best.ckpt",
            learning_rate=0.001,
            input_size=8,
            hidden_size=64,
            classes=24,
            layers=2,
            dropout=0.3,
            gamma=1.0
        )
        models['A-GRU'] = agru
        print("   âœ… A-GRU loaded (Test Acc: 99.65%)")
    except Exception as e:
        print(f"   âŒ A-GRU load failed: {e}")
        return None
    
    # 3. MS-CSGRU
    print("ğŸ“¦ Loading MS-CSGRU...")
    try:
        mscsgru = MSCSGRU.load_from_checkpoint(
            "checkpoints/MSCSGRU_best.ckpt",
            learning_rate=0.001,
            input_size=8,
            hidden_size=64,
            classes=24,
            layers=2,
            dropout=0.3
        )
        models['MS-CSGRU'] = mscsgru
        print("   âœ… MS-CSGRU loaded")
    except Exception as e:
        print(f"   âš ï¸ MS-CSGRU not found, creating new: {e}")
        mscsgru = MSCSGRU(
            learning_rate=0.001,
            input_size=8,
            hidden_size=64,
            classes=24,
            layers=2,
            dropout=0.3
        )
        models['MS-CSGRU'] = mscsgru
    
    return models


def main():
    print("ğŸš€ A-GRU ë…¸ì´ì¦ˆ ê²¬ê³ ì„± ë¶„ì„ ì‹œì‘...\n")
    
    # 1. ëª¨ë¸ ë¡œë“œ
    models = load_trained_models()
    if models is None or 'A-GRU' not in models:
        print("âŒ A-GRU ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # 2. ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    datamodule = DynamicDataModule(
        data_dir='/home/billy/25-1kp/SignGlove_HW/datasets/unified',
        batch_size=32,
        test_size=0.2,
        val_size=0.2,
        use_test_split=True
    )
    print("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n")
    
    # 3. ë…¸ì´ì¦ˆ ë ˆë²¨ ì„¤ì •
    noise_levels = [0.0, 0.02, 0.04, 0.06, 0.08, 0.1]
    
    # 4. ë…¸ì´ì¦ˆ ê²¬ê³ ì„± ë¶„ì„
    results = analyze_noise_robustness(models, datamodule, noise_levels)
    
    # 5. ì‹œê°í™”
    print("\nğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
    plot_noise_robustness(results, noise_levels)
    plot_noise_sensitivity_heatmap(results, noise_levels)
    plot_relative_robustness(results, noise_levels)
    
    # 6. ê²°ê³¼ ìš”ì•½
    print_summary_table(results, noise_levels)
    
    # 7. ê²°ê³¼ ì €ì¥
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    np.savez(OUTPUT_DIR / "noise_robustness_results.npz",
             results=results,
             noise_levels=noise_levels)
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR}/")


if __name__ == "__main__":
    main()

