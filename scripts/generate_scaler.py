#!/usr/bin/env python3
"""
Scaler íŒŒì¼ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
í›ˆë ¨ ì‹œ ì‚¬ìš©í•œ ë™ì¼í•œ ë°ì´í„°ì™€ ì „ì²˜ë¦¬ ê³¼ì •ìœ¼ë¡œ scaler.pkl íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""
import sys
import os
import pickle
from pathlib import Path
import numpy as np
from sklearn.preprocessing import StandardScaler

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.misc.data_preprocessor import preprocess_data
from src.misc.data_loader import find_signglove_files


def generate_scaler(data_dir: str, output_path: str, target_timesteps: int = 87):
    """
    í›ˆë ¨ ë°ì´í„°ë¡œë¶€í„° scalerë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        data_dir: ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        output_path: scaler.pkl ì €ì¥ ê²½ë¡œ
        target_timesteps: íƒ€ì„ìŠ¤í… ê¸¸ì´ (ê¸°ë³¸ê°’: 87)
    """
    print("=" * 80)
    print("ğŸ“Š Scaler íŒŒì¼ ìƒì„±")
    print("=" * 80)
    print()
    
    print(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {data_dir}")
    print(f"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {output_path}")
    print()
    
    # ë°ì´í„° íŒŒì¼ ì°¾ê¸°
    print("ğŸ” ë°ì´í„° íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
    all_files = find_signglove_files(data_dir)
    print(f"âœ… {len(all_files)}ê°œ íŒŒì¼ ë°œê²¬")
    print()
    
    # ë°ì´í„° ì „ì²˜ë¦¬ (scaler ìƒì„±)
    print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ë° scaler ìƒì„± ì¤‘...")
    try:
        X, y, X_padding, class_names, scaler = preprocess_data(
            files=all_files,
            target_timesteps=target_timesteps,
            n_channels=8,
            resampling_method="padding"
        )
        print(f"âœ… Scaler ìƒì„± ì™„ë£Œ!")
        print(f"   ë°ì´í„° í˜•íƒœ: {X.shape}")
        print(f"   í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}")
        print()
        
        # Scaler ì •ë³´ ì¶œë ¥
        print("ğŸ“Š Scaler í†µê³„:")
        print(f"   Mean: {scaler.mean_}")
        print(f"   Scale: {scaler.scale_}")
        print(f"   Variance: {scaler.var_}")
        print()
        
        # Scaler ì €ì¥
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'wb') as f:
            pickle.dump(scaler, f)
        
        print(f"ğŸ’¾ Scaler ì €ì¥ ì™„ë£Œ: {output_file}")
        print(f"   íŒŒì¼ í¬ê¸°: {output_file.stat().st_size / 1024:.2f} KB")
        print()
        
        return scaler
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Scaler íŒŒì¼ ìƒì„±')
    parser.add_argument(
        '-data_dir',
        type=str,
        default='/home/billy/25-1kp/SignGlove-DataAnalysis/unified/unified',
        help='ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬'
    )
    parser.add_argument(
        '-output',
        type=str,
        default='archive/checkpoints_backup/checkpoints_backup/scaler.pkl',
        help='Scaler íŒŒì¼ ì €ì¥ ê²½ë¡œ'
    )
    parser.add_argument(
        '-target_timesteps',
        type=int,
        default=87,
        help='íƒ€ì„ìŠ¤í… ê¸¸ì´ (ê¸°ë³¸ê°’: 87)'
    )
    
    args = parser.parse_args()
    
    generate_scaler(
        data_dir=args.data_dir,
        output_path=args.output,
        target_timesteps=args.target_timesteps
    )
    
    print("=" * 80)
    print("âœ… ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    main()

