"""
A-GRU ê³„ì‚° íš¨ìœ¨ì„± ë¶„ì„ (ìˆ˜ì •ëœ ë²„ì „)
Latency, FLOPs, Parameters ë¹„êµ: GRU vs A-GRU vs MS-CSGRU
"""

import torch
import time
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

from src.models.GRUModels import StackedGRU
from src.models.AGRUModels import AGRUModel
from src.models.MSCSGRUModels import MSCSGRU

# ì¶œë ¥ ë””ë ‰í† ë¦¬
OUTPUT_DIR = Path("visualizations/efficiency_analysis")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def count_parameters(model):
    """ëª¨ë¸ì˜ ì´ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def estimate_flops(model, input_shape=(1, 87, 8)):
    """
    FLOPs ì¶”ì • (ê°„ë‹¨í•œ ë°©ë²•)
    """
    # ë”ë¯¸ ì…ë ¥ ìƒì„±
    x = torch.randn(input_shape)
    x_padding = torch.zeros(input_shape[0], input_shape[1])
    y_targets = torch.randint(0, 24, (input_shape[0],))
    
    # ê°„ë‹¨í•œ FLOPs ì¶”ì • (ì •í™•í•œ ê³„ì‚° ëŒ€ì‹  ê·¼ì‚¬ì¹˜)
    batch_size, seq_len, input_size = input_shape
    
    # ëª¨ë¸ë³„ FLOPs ì¶”ì •
    if model.__class__.__name__ == 'AGRUModel':
        # A-GRU: GRU + A-Net
        # GRU: 3 * (input_size + hidden_size + 1) * hidden_size * batch * seq
        # A-Net: (input_size + hidden_size + 1) * batch * seq
        hidden_size = 64  # A-GRU ê¸°ë³¸ê°’
        gru_flops = 3 * (input_size + hidden_size + 1) * hidden_size * batch_size * seq_len
        anet_flops = (input_size + hidden_size + 1) * batch_size * seq_len
        total_flops = gru_flops + anet_flops
    elif model.__class__.__name__ == 'StackedGRU':
        # Stacked GRU: 2 layers
        hidden_size = 64
        gru_flops = 2 * 3 * (input_size + hidden_size + 1) * hidden_size * batch_size * seq_len
        # Classifier
        classifier_flops = hidden_size * 24 * batch_size  # 24 classes
        total_flops = gru_flops + classifier_flops
    elif model.__class__.__name__ == 'MSCSGRU':
        # MS-CSGRU: CNN + GRU
        # CNN: 3 towers with different kernel sizes
        cnn_flops = 3 * (3*3*8*32 + 5*5*8*32 + 7*7*8*32) * batch_size * seq_len  # 3 towers
        # GRU
        hidden_size = 64
        gru_flops = 3 * (96 + hidden_size + 1) * hidden_size * batch_size * seq_len  # 96 = 3*32
        # Classifier
        classifier_flops = hidden_size * 24 * batch_size
        total_flops = cnn_flops + gru_flops + classifier_flops
    else:
        # ê¸°ë³¸ GRU
        hidden_size = 64
        total_flops = 3 * (input_size + hidden_size + 1) * hidden_size * batch_size * seq_len
    
    return total_flops


def measure_latency(model, input_shape=(1, 87, 8), num_runs=100, warmup=10):
    """
    ì¶”ë¡  ì§€ì—° ì‹œê°„ ì¸¡ì • (CPU) - ìˆ˜ì •ëœ ë²„ì „
    """
    model.eval()
    device = torch.device('cpu')
    model = model.to(device)
    
    # ë”ë¯¸ ë°ì´í„°
    x = torch.randn(input_shape, device=device)
    x_padding = torch.zeros(input_shape[0], input_shape[1], device=device)
    y_targets = torch.randint(0, 24, (input_shape[0],), device=device)
    
    # ëª¨ë¸ íƒ€ì…ì— ë”°ë¥¸ í˜¸ì¶œ ë°©ì‹ ê²°ì •
    model_name = model.__class__.__name__
    
    def forward_pass():
        if model_name == 'AGRUModel':
            return model(x, x_padding, y_targets)
        else:
            return model(x)
    
    # Warmup
    with torch.no_grad():
        for _ in range(warmup):
            try:
                _ = forward_pass()
            except Exception as e:
                print(f"Warmup error: {e}")
                pass
    
    # ì¸¡ì •
    latencies = []
    with torch.no_grad():
        for _ in tqdm(range(num_runs), desc="Measuring latency"):
            start_time = time.perf_counter()
            try:
                _ = forward_pass()
            except Exception as e:
                print(f"Forward pass error: {e}")
                pass
            end_time = time.perf_counter()
            latencies.append((end_time - start_time) * 1000)  # msë¡œ ë³€í™˜
    
    return np.mean(latencies), np.std(latencies)


def create_models():
    """ë¹„êµí•  ëª¨ë¸ë“¤ ìƒì„±"""
    models = {}
    
    # 1. Standard GRU (Stacked)
    print("ğŸ“¦ Creating Standard GRU...")
    gru_model = StackedGRU(
        learning_rate=0.001,
        input_size=8,
        hidden_size=64,
        classes=24,
        layers=2,
        dropout=0.1
    )
    models['GRU'] = gru_model
    
    # 2. A-GRU
    print("ğŸ“¦ Creating A-GRU...")
    agru_model = AGRUModel(
        learning_rate=0.001,
        input_size=8,
        hidden_size=64,
        num_layers=2,
        num_classes=24,
        dropout=0.1,
        gamma=1.0
    )
    models['A-GRU'] = agru_model
    
    # 3. MS-CSGRU
    print("ğŸ“¦ Creating MS-CSGRU...")
    mscsgru_model = MSCSGRU(
        learning_rate=0.001,
        input_size=8,
        num_classes=24,
        dropout=0.1
    )
    models['MS-CSGRU'] = mscsgru_model
    
    return models


def analyze_efficiency():
    """ê³„ì‚° íš¨ìœ¨ì„± ë¶„ì„"""
    print("ğŸš€ A-GRU ê³„ì‚° íš¨ìœ¨ì„± ë¶„ì„ ì‹œì‘...")
    
    # ëª¨ë¸ ìƒì„±
    models = create_models()
    
    # ê²°ê³¼ ì €ì¥
    results = {}
    
    print("\n" + "="*60)
    print("ğŸ“Š ê³„ì‚° íš¨ìœ¨ì„± ë¶„ì„")
    print("="*60)
    
    for name, model in models.items():
        print(f"\nğŸ” Analyzing {name}...")
        
        # Parameters
        params = count_parameters(model)
        print(f"   Parameters: {params:,}")
        
        # FLOPs
        flops = estimate_flops(model)
        print(f"   FLOPs: {flops:,}")
        
        # Latency
        latency_mean, latency_std = measure_latency(model)
        print(f"   Latency: {latency_mean:.3f} Â± {latency_std:.3f} ms")
        
        results[name] = {
            'parameters': params,
            'flops': flops,
            'latency_mean': latency_mean,
            'latency_std': latency_std
        }
    
    return results


def create_visualizations(results):
    """ì‹œê°í™” ìƒì„±"""
    print("\nğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
    
    # ë°ì´í„° ì¤€ë¹„
    models = list(results.keys())
    params = [results[m]['parameters'] for m in models]
    flops = [results[m]['flops'] for m in models]
    latencies = [results[m]['latency_mean'] for m in models]
    
    # 1. íš¨ìœ¨ì„± ë¹„êµ í”Œë¡¯
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('A-GRU vs Baseline Models: Computational Efficiency', fontsize=16, fontweight='bold')
    
    # Parameters ë¹„êµ
    axes[0, 0].bar(models, params, color=['skyblue', 'lightcoral', 'lightgreen'])
    axes[0, 0].set_title('Parameters Comparison', fontweight='bold')
    axes[0, 0].set_ylabel('Parameters')
    axes[0, 0].tick_params(axis='x', rotation=45)
    for i, v in enumerate(params):
        axes[0, 0].text(i, v + max(params)*0.01, f'{v:,}', ha='center', va='bottom')
    
    # FLOPs ë¹„êµ
    axes[0, 1].bar(models, flops, color=['skyblue', 'lightcoral', 'lightgreen'])
    axes[0, 1].set_title('FLOPs Comparison', fontweight='bold')
    axes[0, 1].set_ylabel('FLOPs')
    axes[0, 1].tick_params(axis='x', rotation=45)
    for i, v in enumerate(flops):
        axes[0, 1].text(i, v + max(flops)*0.01, f'{v:,}', ha='center', va='bottom')
    
    # Latency ë¹„êµ
    axes[1, 0].bar(models, latencies, color=['skyblue', 'lightcoral', 'lightgreen'])
    axes[1, 0].set_title('Latency Comparison', fontweight='bold')
    axes[1, 0].set_ylabel('Latency (ms)')
    axes[1, 0].tick_params(axis='x', rotation=45)
    for i, v in enumerate(latencies):
        axes[1, 0].text(i, v + max(latencies)*0.01, f'{v:.2f}ms', ha='center', va='bottom')
    
    # ìƒëŒ€ íš¨ìœ¨ì„± (GRU ê¸°ì¤€)
    gru_params = results['GRU']['parameters']
    gru_flops = results['GRU']['flops']
    gru_latency = results['GRU']['latency_mean']
    
    param_ratios = [results[m]['parameters'] / gru_params for m in models]
    flop_ratios = [results[m]['flops'] / gru_flops for m in models]
    latency_ratios = [results[m]['latency_mean'] / gru_latency for m in models]
    
    x = np.arange(len(models))
    width = 0.25
    
    axes[1, 1].bar(x - width, param_ratios, width, label='Parameters', color='skyblue')
    axes[1, 1].bar(x, flop_ratios, width, label='FLOPs', color='lightcoral')
    axes[1, 1].bar(x + width, latency_ratios, width, label='Latency', color='lightgreen')
    
    axes[1, 1].set_title('Relative Efficiency (vs GRU)', fontweight='bold')
    axes[1, 1].set_ylabel('Ratio')
    axes[1, 1].set_xticks(x)
    axes[1, 1].set_xticklabels(models)
    axes[1, 1].legend()
    axes[1, 1].axhline(y=1.0, color='red', linestyle='--', alpha=0.7)
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'efficiency_comparison_fixed.png', dpi=300, bbox_inches='tight')
    print(f"âœ… íš¨ìœ¨ì„± ë¹„êµ í”Œë¡¯ ì €ì¥: {OUTPUT_DIR / 'efficiency_comparison_fixed.png'}")
    
    # 2. íš¨ìœ¨ì„± íˆíŠ¸ë§µ
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # ë°ì´í„° ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼)
    data = np.array([
        [p/max(params) for p in params],
        [f/max(flops) for f in flops],
        [l/max(latencies) for l in latencies]
    ])
    
    im = ax.imshow(data, cmap='RdYlGn_r', aspect='auto')
    ax.set_xticks(range(len(models)))
    ax.set_xticklabels(models)
    ax.set_yticks(range(3))
    ax.set_yticklabels(['Parameters', 'FLOPs', 'Latency'])
    
    # ê°’ í‘œì‹œ
    for i in range(3):
        for j in range(len(models)):
            text = ax.text(j, i, f'{data[i, j]:.2f}', ha="center", va="center", color="black", fontweight='bold')
    
    ax.set_title('Normalized Efficiency Heatmap\n(Lower is Better)', fontweight='bold')
    plt.colorbar(im, ax=ax)
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'efficiency_heatmap_fixed.png', dpi=300, bbox_inches='tight')
    print(f"âœ… íš¨ìœ¨ì„± íˆíŠ¸ë§µ ì €ì¥: {OUTPUT_DIR / 'efficiency_heatmap_fixed.png'}")
    
    plt.close()


def print_summary(results):
    """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“Š íš¨ìœ¨ì„± ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("="*80)
    print(f"{'Model':<15} {'Parameters':<20} {'FLOPs':<20} {'Latency (ms)':<15}")
    print("-" * 80)
    
    for name, result in results.items():
        params = result['parameters']
        flops = result['flops']
        latency = result['latency_mean']
        print(f"{name:<15} {params:,} ({params/1000:.1f}K) {flops:,} ({flops/1000000:.1f}M) {latency:.3f} Â± {result['latency_std']:.3f}")
    
    print("\n" + "="*80)
    print("ğŸ“ˆ GRU ëŒ€ë¹„ ìƒëŒ€ íš¨ìœ¨ì„±")
    print("="*80)
    print(f"{'Model':<15} {'Params Ratio':<15} {'FLOPs Ratio':<15} {'Latency Ratio':<15}")
    print("-" * 80)
    
    gru_params = results['GRU']['parameters']
    gru_flops = results['GRU']['flops']
    gru_latency = results['GRU']['latency_mean']
    
    for name, result in results.items():
        param_ratio = result['parameters'] / gru_params
        flop_ratio = result['flops'] / gru_flops
        latency_ratio = result['latency_mean'] / gru_latency
        print(f"{name:<15} {param_ratio:.3f}x {flop_ratio:.3f}x {latency_ratio:.3f}x")
    
    print("\n" + "="*80)
    print("ğŸ† A-GRU íš¨ìœ¨ì„± ë¶„ì„")
    print("="*80)
    
    agru_params = results['A-GRU']['parameters']
    agru_latency = results['A-GRU']['latency_mean']
    mscsgru_params = results['MS-CSGRU']['parameters']
    mscsgru_latency = results['MS-CSGRU']['latency_mean']
    
    print(f"A-GRU vs Standard GRU:")
    print(f"  Parameters overhead: +{((agru_params/gru_params-1)*100):.1f}% (+{agru_params-gru_params:,} params)")
    print(f"  Latency overhead: +{((agru_latency/gru_latency-1)*100):.1f}%")
    print()
    print(f"A-GRU vs MS-CSGRU:")
    print(f"  Parameters saving: {((1-agru_params/mscsgru_params)*100):.1f}% ({mscsgru_params-agru_params:,} params)")
    print(f"  Latency overhead: +{((agru_latency/mscsgru_latency-1)*100):.1f}%")


def save_results(results):
    """ê²°ê³¼ ì €ì¥"""
    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # NumPy ë°°ì—´ë¡œ ì €ì¥
    np.savez(OUTPUT_DIR / 'efficiency_results_fixed.npz', 
             models=list(results.keys()),
             parameters=[results[m]['parameters'] for m in results.keys()],
             flops=[results[m]['flops'] for m in results.keys()],
             latencies=[results[m]['latency_mean'] for m in results.keys()])
    
    print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR}/")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # íš¨ìœ¨ì„± ë¶„ì„
    results = analyze_efficiency()
    
    # ì‹œê°í™” ìƒì„±
    create_visualizations(results)
    
    # ê²°ê³¼ ìš”ì•½
    print_summary(results)
    
    # ê²°ê³¼ ì €ì¥
    save_results(results)


if __name__ == "__main__":
    main()
