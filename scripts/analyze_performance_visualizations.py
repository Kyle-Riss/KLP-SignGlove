"""
Performance Visualizations ì¢…í•© ë¶„ì„
1-9ë²ˆ ì‹œê°í™”ì™€ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¹„êµ
"""

import pandas as pd
import numpy as np
from pathlib import Path

print('=' * 80)
print('ğŸ“Š Performance Visualizations ì¢…í•© ë¶„ì„')
print('=' * 80)
print()

# 1. ë°ì´í„° ë¡œë“œ
df = pd.read_csv('inference/performance_visualizations/performance_data.csv')
summary_df = pd.read_csv('inference/performance_visualizations/performance_summary.csv', index_col=0)

print('ğŸ“Œ 1. ê¸°ë³¸ ì„±ëŠ¥ ë°ì´í„° (performance_data.csv)')
print('-' * 80)
print(df.to_string(index=False))
print()

print('ğŸ“Œ 2. ìš”ì•½ í†µê³„ (performance_summary.csv)')
print('-' * 80)
print(summary_df)
print()

# 3. ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸
test_report_file = Path('inference/performance_visualizations/real_test_report_ms3dgru_final.txt')
if test_report_file.exists():
    with open(test_report_file, 'r', encoding='utf-8') as f:
        content = f.read()
        
    print('ğŸ“Œ 3. ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (real_test_report_ms3dgru_final.txt)')
    print('-' * 80)
    lines = content.split('\n')
    for line in lines[:10]:
        if line.strip():
            print(line)
    print()

# 4. ê° ì‹œê°í™” ë°ì´í„° ë¶„ì„
print('=' * 80)
print('ğŸ“Š ì‹œê°í™”ë³„ ë°ì´í„° ìš”ì•½')
print('=' * 80)
print()

# ë°ì´í„°ì…‹ë³„ë¡œ ê·¸ë£¹í™”
datasets = df['Dataset'].unique()
models = df['Model'].unique()

print('1ï¸âƒ£  ë°ì´í„°ì…‹ë³„ Test Accuracy (1_dataset_model_test_accuracy.png ê¸°ì¤€):')
print('-' * 80)
for dataset in datasets:
    dataset_df = df[df['Dataset'] == dataset]
    print(f'\nğŸ“Š {dataset}:')
    for _, row in dataset_df.iterrows():
        print(f'   {row["Model"]:20s}: {row["Test_Acc"]:5.2f}%')
print()

print('2ï¸âƒ£  ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ (2_performance_heatmap.png ê¸°ì¤€):')
print('-' * 80)
model_stats = df.groupby('Model').agg({
    'Test_Acc': ['mean', 'std', 'min', 'max'],
    'Test_F1': ['mean', 'std'],
    'Test_Loss': ['mean', 'std']
}).round(2)
print(model_stats)
print()

print('3ï¸âƒ£  íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± (3_parameter_efficiency.png ê¸°ì¤€):')
print('-' * 80)
for model in models:
    model_df = df[df['Model'] == model].iloc[0]
    params_k = model_df['Parameters'] / 1000
    avg_acc = df[df['Model'] == model]['Test_Acc'].mean()
    efficiency = avg_acc / params_k  # ì •í™•ë„ / íŒŒë¼ë¯¸í„°(K)
    print(f'   {model:20s}: {avg_acc:5.2f}% / {params_k:6.1f}K params = {efficiency:.4f} íš¨ìœ¨')
print()

print('4ï¸âƒ£  Overfitting ë¶„ì„ (4_overfitting_analysis.png ê¸°ì¤€):')
print('-' * 80)
for dataset in datasets:
    dataset_df = df[df['Dataset'] == dataset]
    print(f'\nğŸ“Š {dataset}:')
    for _, row in dataset_df.iterrows():
        train_acc = row['Train_Acc']
        val_acc = row['Val_Acc']
        test_acc = row['Test_Acc']
        gap = train_acc - test_acc
        status = 'âœ… ê²½ë¯¸' if gap < 1.5 else 'âš ï¸  ì¤‘ê°„' if gap < 3 else 'âŒ ì‹¬í•¨'
        print(f'   {row["Model"]:20s}: Train={train_acc:5.2f}%, Val={val_acc:5.2f}%, Test={test_acc:5.2f}% | Gap={gap:4.2f}% {status}')
print()

print('5ï¸âƒ£  Loss ë¹„êµ (5_loss_comparison.png ê¸°ì¤€):')
print('-' * 80)
for dataset in datasets:
    dataset_df = df[df['Dataset'] == dataset]
    print(f'\nğŸ“Š {dataset}:')
    for _, row in dataset_df.iterrows():
        val_loss = row['Val_Loss']
        test_loss = row['Test_Loss']
        print(f'   {row["Model"]:20s}: Val Loss={val_loss:.3f}, Test Loss={test_loss:.3f}')
print()

print('6ï¸âƒ£  ëª¨ë¸ ì„±ëŠ¥ ë­í‚¹ (6_model_ranking.png ê¸°ì¤€):')
print('-' * 80)
for dataset in datasets:
    dataset_df = df[df['Dataset'] == dataset].sort_values('Test_Acc', ascending=False)
    print(f'\nğŸ“Š {dataset} (ìˆœìœ„ìˆœ):')
    for rank, (_, row) in enumerate(dataset_df.iterrows(), 1):
        print(f'   {rank}. {row["Model"]:20s}: {row["Test_Acc"]:5.2f}%')
print()

print('7ï¸âƒ£  í’ˆì§ˆ ë¶„ì„ (7_quality_analysis.png ê¸°ì¤€):')
print('-' * 80)
for dataset in datasets:
    dataset_df = df[df['Dataset'] == dataset]
    print(f'\nğŸ“Š {dataset}:')
    for _, row in dataset_df.iterrows():
        stability = row['Stability']
        overfitting = row['Overfitting']
        test_acc = row['Test_Acc']
        quality_score = row['Stability_Score'] + row['Overfitting_Score']
        print(f'   {row["Model"]:20s}: Acc={test_acc:5.2f}%, Stability={stability:10s}, Overfitting={overfitting:6s}, Quality={quality_score}')
print()

print('8ï¸âƒ£  ì¢…í•© ì„±ëŠ¥ ë¹„êµ (8_comprehensive_radar.png ê¸°ì¤€):')
print('-' * 80)
for model in models:
    model_df = df[df['Model'] == model]
    avg_acc = model_df['Test_Acc'].mean()
    avg_f1 = model_df['Test_F1'].mean()
    avg_params = model_df['Parameters'].iloc[0]
    avg_stability = model_df['Stability_Score'].mean()
    avg_overfitting = model_df['Overfitting_Score'].mean()
    
    # ì •ê·œí™”ëœ ì ìˆ˜
    norm_acc = avg_acc / 100
    norm_f1 = avg_f1
    norm_efficiency = 1 - (avg_params / 200000)  # íŒŒë¼ë¯¸í„°ê°€ ì ì„ìˆ˜ë¡ ë†’ìŒ
    norm_stability = avg_stability / 3
    norm_overfitting = avg_overfitting / 3
    
    print(f'\n   {model}:')
    print(f'      ì •í™•ë„: {norm_acc:.3f} | F1: {norm_f1:.3f} | íš¨ìœ¨: {norm_efficiency:.3f} | ì•ˆì •ì„±: {norm_stability:.3f} | ê³¼ì í•©ë°©ì§€: {norm_overfitting:.3f}')
print()

print('9ï¸âƒ£  ìƒì„¸ ë¹„êµ (9_detailed_comparison.png ê¸°ì¤€):')
print('-' * 80)
metrics = ['Test_Acc', 'Test_F1', 'Test_Loss', 'Parameters']
for metric in metrics:
    print(f'\nğŸ“Š {metric}:')
    pivot = df.pivot(index='Model', columns='Dataset', values=metric)
    print(pivot.to_string())
print()

# 5. ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì™€ ë¹„êµ
print('=' * 80)
print('âš ï¸  ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¹„êµ')
print('=' * 80)
print()
print('ğŸ“Œ í›ˆë ¨ ì‹œ ì„±ëŠ¥ (performance_data.csv):')
ms3dgru_train = df[df['Model'] == 'MS3DGRU']
print(f'   í‰ê·  Test Accuracy: {ms3dgru_train["Test_Acc"].mean():.2f}%')
print(f'   yubeen & jaeyeon: {ms3dgru_train[ms3dgru_train["Dataset"] == "yubeen & jaeyeon"]["Test_Acc"].values[0]:.2f}%')
print()

print('ğŸ“Œ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ (real_test_report):')
print(f'   Test Accuracy: 4.16% âš ï¸')
print(f'   ë¬¸ì œ: ëª¨ë¸ì´ ëª¨ë“  ì…ë ¥ì„ í´ë˜ìŠ¤ 13 (ã…)ë¡œë§Œ ì˜ˆì¸¡')
print()

print('=' * 80)
print('ğŸ” ë¬¸ì œ ë¶„ì„')
print('=' * 80)
print()
print('1. ì„±ëŠ¥ ì°¨ì´:')
print('   - í›ˆë ¨ ë¡œê·¸: 98.78%')
print('   - ì²´í¬í¬ì¸íŠ¸ ì •ë³´: 98.78%')
print('   - ì§ì ‘ í…ŒìŠ¤íŠ¸: 4.16%')
print('   â†’ ì²´í¬í¬ì¸íŠ¸ ì €ì¥/ë¡œë“œ ë¬¸ì œ ê°€ëŠ¥ì„± ë†’ìŒ')
print()
print('2. ê°€ëŠ¥í•œ ì›ì¸:')
print('   - ì²´í¬í¬ì¸íŠ¸ê°€ ì˜ëª»ëœ ëª¨ë¸ ìƒíƒœ ì €ì¥')
print('   - ëª¨ë¸ ë¡œë“œ ì‹œ íŒŒë¼ë¯¸í„° ë¶ˆì¼ì¹˜')
print('   - ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì°¨ì´')
print('   - Dropout/Training mode ì°¨ì´')
print()
print('3. ê¶Œì¥ ì‚¬í•­:')
print('   - PyTorch Lightning Trainer.test()ë¡œ ì¬ê²€ì¦')
print('   - ì²´í¬í¬ì¸íŠ¸ ì¬ì €ì¥ (í›ˆë ¨ ì™„ë£Œ ì§í›„)')
print('   - ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¼ì¹˜ í™•ì¸')
print()

print('=' * 80)

