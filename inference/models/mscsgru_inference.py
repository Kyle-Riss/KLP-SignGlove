"""
MS-CSGRU ì¶”ë¡  ì „ìš© ëª¨ë¸

í›ˆë ¨ ê´€ë ¨ ì½”ë“œê°€ ì œê±°ëœ ê²½ëŸ‰í™”ëœ MSCSGRU êµ¬í˜„
ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ì—¬ ì¶”ë¡ ë§Œ ìˆ˜í–‰
"""

import torch
import torch.nn as nn
from typing import Tuple
from torch import Tensor


class MSCSGRUInference(nn.Module):
    """
    MS-CSGRU: Multi-Scale CNN + Stacked GRU ì¶”ë¡  ì „ìš© ëª¨ë¸
    
    í›ˆë ¨ ê´€ë ¨ ì½”ë“œ(loss, learning_rate ë“±)ê°€ ì œê±°ëœ ê²½ëŸ‰í™” ë²„ì „
    ì¶”ë¡  ì†ë„ì™€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì— ìµœì í™”
    """
    
    def __init__(
        self,
        input_size: int = 8,
        hidden_size: int = 64,
        classes: int = 24,
        cnn_filters: int = 32,
        dropout: float = 0.3
    ):
        """
        Args:
            input_size: ì…ë ¥ ì±„ë„ ìˆ˜ (ê¸°ë³¸: 8 - flex1-5 + yaw, pitch, roll)
            hidden_size: GRU íˆë“  ì‚¬ì´ì¦ˆ (ê¸°ë³¸: 64)
            classes: ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜ (ê¸°ë³¸: 24 - ììŒ 14ê°œ + ëª¨ìŒ 10ê°œ)
            cnn_filters: CNN í•„í„° ìˆ˜ (ê¸°ë³¸: 32)
            dropout: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ (ê¸°ë³¸: 0.3)
        """
        super().__init__()
        
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.classes = classes
        self.cnn_filters = cnn_filters
        
        # Multi-Scale CNN: 3ê°œ íƒ€ì›Œ ë³‘ë ¬ ì²˜ë¦¬
        self.tower1 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 3, padding=1),
            nn.BatchNorm1d(cnn_filters),
            nn.ReLU()
        )
        self.tower2 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 5, padding=2),
            nn.BatchNorm1d(cnn_filters),
            nn.ReLU()
        )
        self.tower3 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 7, padding=3),
            nn.BatchNorm1d(cnn_filters),
            nn.ReLU()
        )
        
        # CNN í›„ì²˜ë¦¬
        self.cnn_post = nn.Sequential(
            nn.BatchNorm1d(cnn_filters * 3),
            nn.ReLU(),
            nn.MaxPool1d(2, 2),
            nn.Dropout(dropout)
        )
        
        # Stacked GRU
        self.gru1 = nn.GRU(cnn_filters * 3, hidden_size, 1, batch_first=True)
        self.gru2 = nn.GRU(hidden_size, hidden_size, 1, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        
        # ë¶„ë¥˜ê¸°
        self.output_layers = nn.Sequential(
            nn.Linear(hidden_size, 2 * hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(2 * hidden_size, classes)
        )
    
    def forward(self, x: Tensor) -> Tensor:
        """
        ì¶”ë¡  ì „ìš© forward ë©”ì„œë“œ
        
        Args:
            x: ì…ë ¥ í…ì„œ (batch_size, time_steps, channels)
        
        Returns:
            logits: í´ë˜ìŠ¤ë³„ ë¡œì§“ (batch_size, classes)
        """
        # Multi-Scale CNN
        x_conv = x.transpose(1, 2)  # (batch, channels, time)
        t1 = self.tower1(x_conv)
        t2 = self.tower2(x_conv)
        t3 = self.tower3(x_conv)
        conv_out = torch.cat([t1, t2, t3], dim=1)
        conv_out = self.cnn_post(conv_out)
        
        # Stacked GRU
        conv_out = conv_out.transpose(1, 2)  # (batch, time, channels)
        gru1_out, _ = self.gru1(conv_out)
        gru1_out = self.dropout(gru1_out)
        gru2_out, _ = self.gru2(gru1_out)
        
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ íŠ¹ì§• ì‚¬ìš©
        final_features = gru2_out[:, -1, :]
        
        # ë¶„ë¥˜
        logits = self.output_layers(final_features)
        
        return logits
    
    @torch.no_grad()
    def predict(self, x: Tensor) -> Tensor:
        """
        ì¶”ë¡  ì „ìš© ë©”ì„œë“œ (gradient ê³„ì‚° ì—†ìŒ)
        
        Args:
            x: ì…ë ¥ í…ì„œ (batch_size, time_steps, channels)
        
        Returns:
            logits: í´ë˜ìŠ¤ë³„ ë¡œì§“ (batch_size, classes)
        """
        self.eval()
        return self.forward(x)
    
    @torch.no_grad()
    def predict_proba(self, x: Tensor) -> Tensor:
        """
        í™•ë¥ ê°’ ì˜ˆì¸¡
        
        Args:
            x: ì…ë ¥ í…ì„œ (batch_size, time_steps, channels)
        
        Returns:
            probabilities: í´ë˜ìŠ¤ë³„ í™•ë¥  (batch_size, classes)
        """
        self.eval()
        logits = self.forward(x)
        probabilities = torch.softmax(logits, dim=-1)
        return probabilities
    
    @torch.no_grad()
    def predict_class(self, x: Tensor) -> Tuple[Tensor, Tensor]:
        """
        í´ë˜ìŠ¤ ì˜ˆì¸¡ + í™•ë¥ 
        
        Args:
            x: ì…ë ¥ í…ì„œ (batch_size, time_steps, channels)
        
        Returns:
            predicted_classes: ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ (batch_size,)
            confidences: ì˜ˆì¸¡ í™•ë¥  (batch_size,)
        """
        self.eval()
        probabilities = self.predict_proba(x)
        confidences, predicted_classes = torch.max(probabilities, dim=-1)
        return predicted_classes, confidences
    
    @classmethod
    def from_checkpoint(cls, checkpoint_path: str, **model_kwargs):
        """
        ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ
        
        Args:
            checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ (.ckpt ë˜ëŠ” .pt)
            **model_kwargs: ëª¨ë¸ ì´ˆê¸°í™” ì¸ì
        
        Returns:
            model: ë¡œë“œëœ ëª¨ë¸ (í‰ê°€ ëª¨ë“œ)
        """
        # ëª¨ë¸ ì´ˆê¸°í™”
        model = cls(**model_kwargs)
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # Lightning ì²´í¬í¬ì¸íŠ¸ì¸ ê²½ìš°
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
            # 'model.' ì ‘ë‘ì‚¬ ì œê±°
            new_state_dict = {}
            for key, value in state_dict.items():
                if key.startswith('model.'):
                    new_key = key[6:]  # 'model.' ì œê±°
                    new_state_dict[new_key] = value
                else:
                    new_state_dict[key] = value
            model.load_state_dict(new_state_dict, strict=False)
        else:
            # ì¼ë°˜ PyTorch ì²´í¬í¬ì¸íŠ¸ì¸ ê²½ìš°
            model.load_state_dict(checkpoint, strict=False)
        
        model.eval()
        return model
    
    def count_parameters(self) -> int:
        """
        í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
        
        Returns:
            num_params: íŒŒë¼ë¯¸í„° ìˆ˜
        """
        return sum(p.numel() for p in self.parameters() if p.requires_grad)
    
    def get_model_info(self) -> dict:
        """
        ëª¨ë¸ ì •ë³´ ë°˜í™˜
        
        Returns:
            info: ëª¨ë¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        return {
            'model_type': 'MS-CSGRU',
            'input_size': self.input_size,
            'hidden_size': self.hidden_size,
            'classes': self.classes,
            'cnn_filters': self.cnn_filters,
            'total_parameters': self.count_parameters()
        }


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸ§ª MSCSGRUInference í…ŒìŠ¤íŠ¸...")
    
    # ëª¨ë¸ ìƒì„±
    model = MSCSGRUInference(
        input_size=8,
        hidden_size=64,
        classes=24,
        cnn_filters=32
    )
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    info = model.get_model_info()
    print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´:")
    for key, value in info.items():
        print(f"  {key}: {value}")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    batch_size, time_steps, input_channels = 4, 87, 8
    x = torch.randn(batch_size, time_steps, input_channels)
    
    # ì¶”ë¡  í…ŒìŠ¤íŠ¸
    print(f"\nğŸ” ì¶”ë¡  í…ŒìŠ¤íŠ¸:")
    print(f"  ì…ë ¥ shape: {x.shape}")
    
    logits = model.predict(x)
    print(f"  ë¡œì§“ shape: {logits.shape}")
    
    probabilities = model.predict_proba(x)
    print(f"  í™•ë¥  shape: {probabilities.shape}")
    
    predicted_classes, confidences = model.predict_class(x)
    print(f"  ì˜ˆì¸¡ í´ë˜ìŠ¤: {predicted_classes.tolist()}")
    print(f"  í™•ë¥ : {confidences.tolist()}")
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")




