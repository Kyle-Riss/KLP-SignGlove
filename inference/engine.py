"""
SignGlove ì¶”ë¡  ì—”ì§„

ëª¨ë¸ ë¡œë”©, ì „ì²˜ë¦¬, ì¶”ë¡ , í›„ì²˜ë¦¬ë¥¼ í†µí•©í•œ ê³ ìˆ˜ì¤€ API
"""

import torch
import numpy as np
from pathlib import Path
from typing import Union, List, Dict

from .models.mscsgru_inference import MSCSGRUInference
from .utils.preprocessor import InferencePreprocessor
from .utils.postprocessor import InferencePostprocessor


class SignGloveInference:
    """
    SignGlove í†µí•© ì¶”ë¡  ì—”ì§„
    
    ëª¨ë¸ ë¡œë”©ë¶€í„° ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ê¹Œì§€ ëª¨ë“  ê³¼ì •ì„ ê´€ë¦¬
    ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ê³ ìˆ˜ì¤€ API ì œê³µ
    """
    
    def __init__(
        self,
        model_path: str,
        model_type: str = 'MSCSGRU',
        input_size: int = 8,
        hidden_size: int = 64,
        classes: int = 24,
        cnn_filters: int = 32,
        dropout: float = 0.3,
        target_timesteps: int = 87,
        device: str = None,
        class_names: List[str] = None,
        scaler_path: str = 'best_model/scaler.pkl',
        single_predict_device: str = 'cpu',
        enable_dtw: bool = False
    ):
        """
        Args:
            model_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
            model_type: ëª¨ë¸ íƒ€ì… (í˜„ì¬ 'MSCSGRU'ë§Œ ì§€ì›)
            input_size: ì…ë ¥ ì±„ë„ ìˆ˜
            hidden_size: íˆë“  ì‚¬ì´ì¦ˆ
            classes: í´ë˜ìŠ¤ ìˆ˜
            cnn_filters: CNN í•„í„° ìˆ˜
            dropout: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
            target_timesteps: íƒ€ì„ìŠ¤í… ê¸¸ì´
            device: ë””ë°”ì´ìŠ¤ ('cuda', 'cpu', None=ìë™)
            class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        self.model_path = Path(model_path)
        self.model_type = model_type
        self.target_timesteps = target_timesteps
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        print(f"ğŸš€ SignGlove ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”...")
        print(f"  ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ë¡œë”©
        self.model = self._load_model(
            input_size=input_size,
            hidden_size=hidden_size,
            classes=classes,
            cnn_filters=cnn_filters,
            dropout=dropout
        )
        self.model.to(self.device)
        
        # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (í›ˆë ¨ ì‹œ ì €ì¥ëœ StandardScaler ê°•ì œ ì‚¬ìš©)
        try:
            self.preprocessor = InferencePreprocessor.load_scaler(
                scaler_path,
                target_timesteps=target_timesteps,
                n_channels=input_size
            )
            print(f"  Scaler loaded from: {scaler_path}")
        except Exception as e:
            # ì•ˆì „ì¥ì¹˜: ë¡œë“œ ì‹¤íŒ¨ ì‹œ ëª…ì‹œì ìœ¼ë¡œ ì˜ˆì™¸ ì „íŒŒí•´ ë¬´ê²°ì„± ë³´ì¥
            raise FileNotFoundError(
                f"StandardScaler file not found or invalid at '{scaler_path}'. "
                f"Train-time scaler must be provided. Original error: {e}"
            )
        
        # í›„ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        self.postprocessor = InferencePostprocessor(class_names=class_names)

        # ì˜µì…˜ ì €ì¥
        self.single_predict_device = single_predict_device or 'cpu'
        self.enable_dtw = bool(enable_dtw)
        
        print(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ!")
        print(f"  ëª¨ë¸: {self.model_type}")
        print(f"  íŒŒë¼ë¯¸í„° ìˆ˜: {self.model.count_parameters():,}")
        print(f"  í´ë˜ìŠ¤ ìˆ˜: {classes}")
    
    def _load_model(self, **model_kwargs) -> MSCSGRUInference:
        """ëª¨ë¸ ë¡œë”©"""
        if self.model_type == 'MSCSGRU':
            model = MSCSGRUInference.from_checkpoint(
                str(self.model_path),
                **model_kwargs
            )
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {self.model_type}")
        
        return model
    
    def predict_single(
        self,
        raw_data: Union[np.ndarray, List[List[float]]],
        top_k: int = 5,
        return_all_info: bool = True
    ) -> Dict:
        """
        ë‹¨ì¼ ìƒ˜í”Œ ì˜ˆì¸¡
        
        Args:
            raw_data: ì›ì‹œ ì„¼ì„œ ë°ì´í„° (timesteps, channels)
            top_k: ìƒìœ„ Kê°œ í´ë˜ìŠ¤ ë°˜í™˜
            return_all_info: Trueì´ë©´ ëª¨ë“  ì •ë³´ ë°˜í™˜, Falseì´ë©´ ìµœìƒìœ„ ì˜ˆì¸¡ë§Œ
        
        Returns:
            result: ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì „ì²˜ë¦¬
        x = self.preprocessor.preprocess_single(raw_data, normalize=True)
        # ë‹¨ì¼ ìƒ˜í”Œì€ latency ìµœì†Œí™”ë¥¼ ìœ„í•´ ê¸°ë³¸ì ìœ¼ë¡œ CPUì—ì„œ ì²˜ë¦¬
        run_device = torch.device(self.single_predict_device)
        x = x.to(run_device)
        
        # ì¶”ë¡  (í•„ìš” ì‹œ ì„ì‹œë¡œ ëª¨ë¸ì„ í•´ë‹¹ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™)
        original_device = next(self.model.parameters()).device
        if original_device != run_device:
            self.model.to(run_device)
        logits = self.model.predict(x)
        if original_device != run_device:
            self.model.to(original_device)
        
        # í›„ì²˜ë¦¬
        if return_all_info:
            result = self.postprocessor.format_single_prediction(logits, top_k=top_k)
        else:
            predicted_class, confidence = self.postprocessor.logits_to_class(logits)
            result = {
                'predicted_class': self.postprocessor.class_names[predicted_class.item()],
                'confidence': float(confidence.item())
            }
        
        return result
    
    def predict_batch(
        self,
        raw_data_list: List[Union[np.ndarray, List[List[float]]]],
        top_k: int = 5
    ) -> List[Dict]:
        """
        ë°°ì¹˜ ì˜ˆì¸¡
        
        Args:
            raw_data_list: ì›ì‹œ ì„¼ì„œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            top_k: ìƒìœ„ Kê°œ í´ë˜ìŠ¤ ë°˜í™˜
        
        Returns:
            results: ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ì „ì²˜ë¦¬
        x = self.preprocessor.preprocess_batch(raw_data_list, normalize=True)
        x = x.to(self.device)
        
        # ì¶”ë¡ 
        logits = self.model.predict(x)
        
        # í›„ì²˜ë¦¬
        results = self.postprocessor.format_batch_predictions(logits, top_k=top_k)
        
        return results
    
    def predict_with_details(
        self,
        raw_data: Union[np.ndarray, List[List[float]]]
    ) -> Dict:
        """
        ìƒì„¸ ì •ë³´ë¥¼ í¬í•¨í•œ ì˜ˆì¸¡
        
        Args:
            raw_data: ì›ì‹œ ì„¼ì„œ ë°ì´í„° (timesteps, channels)
        
        Returns:
            result: ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼
                - predicted_class: ì˜ˆì¸¡ í´ë˜ìŠ¤
                - confidence: ì˜ˆì¸¡ í™•ë¥ 
                - top_k_predictions: ìƒìœ„ Kê°œ ì˜ˆì¸¡
                - all_class_probabilities: ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥ 
                - input_shape: ì…ë ¥ ë°ì´í„° shape
        """
        # ì…ë ¥ ì •ë³´
        if isinstance(raw_data, list):
            raw_data = np.array(raw_data)
        input_shape = raw_data.shape
        
        # ì „ì²˜ë¦¬
        x = self.preprocessor.preprocess_single(raw_data, normalize=True)
        x = x.to(self.device)
        
        # ì¶”ë¡ 
        logits = self.model.predict(x)
        
        # í›„ì²˜ë¦¬
        result = self.postprocessor.format_single_prediction(logits, top_k=5)
        
        # ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥  ì¶”ê°€
        all_probs = self.postprocessor.get_class_probabilities(logits)
        result['all_class_probabilities'] = all_probs
        result['input_shape'] = input_shape
        
        return result
    
    def get_model_info(self) -> Dict:
        """
        ëª¨ë¸ ì •ë³´ ë°˜í™˜
        
        Returns:
            info: ëª¨ë¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        info = self.model.get_model_info()
        info.update({
            'device': str(self.device),
            'target_timesteps': self.target_timesteps,
            'model_path': str(self.model_path),
            'class_names': self.postprocessor.class_names
        })
        return info
    
    def print_prediction(self, prediction: Dict):
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
        
        Args:
            prediction: predict_single ë˜ëŠ” predict_with_detailsì˜ ë°˜í™˜ê°’
        """
        self.postprocessor.print_prediction(prediction)


# í¸ì˜ í•¨ìˆ˜
def load_inference_engine(
    model_path: str,
    device: str = None,
    **kwargs
) -> SignGloveInference:
    """
    ì¶”ë¡  ì—”ì§„ ë¡œë”© í¸ì˜ í•¨ìˆ˜
    
    Args:
        model_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
        device: ë””ë°”ì´ìŠ¤
        **kwargs: SignGloveInference ì´ˆê¸°í™” ì¸ì
    
    Returns:
        engine: ì¶”ë¡  ì—”ì§„
    """
    return SignGloveInference(model_path=model_path, device=device, **kwargs)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸ§ª SignGloveInference í…ŒìŠ¤íŠ¸...")
    
    # ë”ë¯¸ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš°)
    print("\nâš ï¸  ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    print("í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•˜ì„¸ìš”:")
    print("""
    # ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”
    engine = SignGloveInference(
        model_path='best_model/best_model.ckpt',
        model_type='MSCSGRU',
        device='cpu'
    )
    
    # ë‹¨ì¼ ìƒ˜í”Œ ì˜ˆì¸¡
    raw_data = np.random.randn(87, 8)  # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    result = engine.predict_single(raw_data)
    engine.print_prediction(result)
    
    # ë°°ì¹˜ ì˜ˆì¸¡
    raw_data_list = [np.random.randn(87, 8) for _ in range(5)]
    results = engine.predict_batch(raw_data_list)
    
    # ëª¨ë¸ ì •ë³´
    info = engine.get_model_info()
    print(info)
    """)

