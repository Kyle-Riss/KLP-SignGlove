"""
ì¶”ë¡  ì „ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°

ì„¼ì„œ ë°ì´í„° ì •ê·œí™”, íŒ¨ë”©, íŠ¸ë ì¼€ì´ì…˜ ë“±
"""

import numpy as np
import torch
from typing import Union, List
import pickle
from pathlib import Path


class InferencePreprocessor:
    """
    ì¶”ë¡  ì „ì²˜ë¦¬ê¸°
    
    í›ˆë ¨ ì‹œ ì‚¬ìš©í•œ ì •ê·œí™” íŒŒë¼ë¯¸í„°ë¥¼ ë¡œë”©í•˜ì—¬
    ì¼ê´€ëœ ì „ì²˜ë¦¬ ìˆ˜í–‰
    """
    
    def __init__(
        self,
        target_timesteps: int = 87,
        n_channels: int = 8,
        scaler=None
    ):
        """
        Args:
            target_timesteps: íƒ€ê²Ÿ íƒ€ì„ìŠ¤í… ê¸¸ì´
            n_channels: ì„¼ì„œ ì±„ë„ ìˆ˜
            scaler: sklearn StandardScaler ê°ì²´ (Noneì´ë©´ ì •ê·œí™” ì•ˆí•¨)
        """
        self.target_timesteps = target_timesteps
        self.n_channels = n_channels
        self.scaler = scaler
    
    def pad_or_truncate(
        self,
        data: np.ndarray
    ) -> np.ndarray:
        """
        ë°ì´í„°ë¥¼ íƒ€ê²Ÿ ê¸¸ì´ë¡œ íŒ¨ë”© ë˜ëŠ” íŠ¸ë ì¼€ì´ì…˜
        
        Args:
            data: (timesteps, channels) ì„¼ì„œ ë°ì´í„°
        
        Returns:
            processed: (target_timesteps, channels) ì²˜ë¦¬ëœ ë°ì´í„°
        """
        current_timesteps = data.shape[0]
        
        if current_timesteps == self.target_timesteps:
            return data
        elif current_timesteps < self.target_timesteps:
            # íŒ¨ë”©
            padding = np.zeros((self.target_timesteps - current_timesteps, self.n_channels))
            return np.vstack([data, padding])
        else:
            # íŠ¸ë ì¼€ì´ì…˜ (ì•ë¶€ë¶„ ì‚¬ìš©)
            return data[:self.target_timesteps]
    
    def normalize(
        self,
        data: np.ndarray
    ) -> np.ndarray:
        """
        ë°ì´í„° ì •ê·œí™”
        
        Args:
            data: (timesteps, channels) ì„¼ì„œ ë°ì´í„°
        
        Returns:
            normalized: ì •ê·œí™”ëœ ë°ì´í„°
        """
        if self.scaler is None:
            return data
        
        # StandardScaler ì ìš©
        original_shape = data.shape
        data_flat = data.reshape(-1, self.n_channels)
        normalized_flat = self.scaler.transform(data_flat)
        normalized = normalized_flat.reshape(original_shape)
        
        return normalized
    
    def preprocess_single(
        self,
        raw_data: Union[np.ndarray, List[List[float]]],
        normalize: bool = True
    ) -> torch.Tensor:
        """
        ë‹¨ì¼ ìƒ˜í”Œ ì „ì²˜ë¦¬
        
        Args:
            raw_data: ì›ì‹œ ì„¼ì„œ ë°ì´í„°
            normalize: ì •ê·œí™” ì—¬ë¶€
        
        Returns:
            tensor: (1, target_timesteps, channels) í…ì„œ
        """
        # numpy ë³€í™˜
        if isinstance(raw_data, list):
            data = np.array(raw_data, dtype=np.float32)
        else:
            data = raw_data.astype(np.float32)
        
        # íŒ¨ë”©/íŠ¸ë ì¼€ì´ì…˜
        data = self.pad_or_truncate(data)
        
        # ì •ê·œí™”
        if normalize:
            data = self.normalize(data)
        
        # í…ì„œ ë³€í™˜
        tensor = torch.from_numpy(data).unsqueeze(0)  # (1, timesteps, channels)
        
        return tensor
    
    def preprocess_batch(
        self,
        raw_data_list: List[Union[np.ndarray, List[List[float]]]],
        normalize: bool = True
    ) -> torch.Tensor:
        """
        ë°°ì¹˜ ì „ì²˜ë¦¬
        
        Args:
            raw_data_list: ì›ì‹œ ì„¼ì„œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            normalize: ì •ê·œí™” ì—¬ë¶€
        
        Returns:
            tensor: (batch_size, target_timesteps, channels) í…ì„œ
        """
        processed_list = []
        
        for raw_data in raw_data_list:
            # numpy ë³€í™˜
            if isinstance(raw_data, list):
                data = np.array(raw_data, dtype=np.float32)
            else:
                data = raw_data.astype(np.float32)
            
            # íŒ¨ë”©/íŠ¸ë ì¼€ì´ì…˜
            data = self.pad_or_truncate(data)
            
            # ì •ê·œí™”
            if normalize:
                data = self.normalize(data)
            
            processed_list.append(data)
        
        # ë°°ì¹˜ í…ì„œë¡œ ë³€í™˜
        batch_array = np.stack(processed_list, axis=0)
        tensor = torch.from_numpy(batch_array)
        
        return tensor
    
    @classmethod
    def load_scaler(
        cls,
        scaler_path: str,
        target_timesteps: int = 87,
        n_channels: int = 8
    ) -> 'InferencePreprocessor':
        """
        ì €ì¥ëœ scalerë¥¼ ë¡œë”©í•˜ì—¬ ì „ì²˜ë¦¬ê¸° ìƒì„±
        
        Args:
            scaler_path: scaler íŒŒì¼ ê²½ë¡œ
            target_timesteps: íƒ€ê²Ÿ íƒ€ì„ìŠ¤í… ê¸¸ì´
            n_channels: ì„¼ì„œ ì±„ë„ ìˆ˜
        
        Returns:
            preprocessor: ì „ì²˜ë¦¬ê¸° ì¸ìŠ¤í„´ìŠ¤
        """
        scaler_file = Path(scaler_path)
        
        if scaler_file.exists():
            with open(scaler_file, 'rb') as f:
                scaler = pickle.load(f)
        else:
            raise FileNotFoundError(f"Scaler íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scaler_path}")
        
        return cls(
            target_timesteps=target_timesteps,
            n_channels=n_channels,
            scaler=scaler
        )
    
    def save_scaler(self, scaler_path: str):
        """
        Scaler ì €ì¥
        
        Args:
            scaler_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        if self.scaler is None:
            raise ValueError("ì €ì¥í•  scalerê°€ ì—†ìŠµë‹ˆë‹¤")
        
        with open(scaler_path, 'wb') as f:
            pickle.dump(self.scaler, f)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸ§ª InferencePreprocessor í…ŒìŠ¤íŠ¸...")
    
    # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (scaler ì—†ì´)
    preprocessor = InferencePreprocessor(target_timesteps=87, n_channels=8)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    print("\n1ï¸âƒ£ ë‹¨ì¼ ìƒ˜í”Œ ì „ì²˜ë¦¬:")
    raw_data = np.random.randn(50, 8)  # ì§§ì€ ì‹œí€€ìŠ¤
    tensor = preprocessor.preprocess_single(raw_data, normalize=False)
    print(f"  ì…ë ¥ shape: {raw_data.shape}")
    print(f"  ì¶œë ¥ shape: {tensor.shape}")
    print(f"  âœ… íŒ¨ë”© ì„±ê³µ!")
    
    # ë°°ì¹˜ ì „ì²˜ë¦¬
    print("\n2ï¸âƒ£ ë°°ì¹˜ ì „ì²˜ë¦¬:")
    raw_data_list = [
        np.random.randn(50, 8),
        np.random.randn(100, 8),
        np.random.randn(87, 8)
    ]
    batch_tensor = preprocessor.preprocess_batch(raw_data_list, normalize=False)
    print(f"  ë°°ì¹˜ í¬ê¸°: {len(raw_data_list)}")
    print(f"  ì¶œë ¥ shape: {batch_tensor.shape}")
    print(f"  âœ… ë°°ì¹˜ ì „ì²˜ë¦¬ ì„±ê³µ!")
