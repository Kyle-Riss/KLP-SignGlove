"""
ì¶”ë¡  ì „ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°

ì›ì‹œ ì„¼ì„œ ë°ì´í„°ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""

import numpy as np
import torch
from typing import Union, List
from sklearn.preprocessing import StandardScaler


class InferencePreprocessor:
    """
    ì¶”ë¡ ìš© ë°ì´í„° ì „ì²˜ë¦¬ê¸°
    
    ì›ì‹œ ì„¼ì„œ ë°ì´í„°ë¥¼ ëª¨ë¸ ì…ë ¥ í…ì„œë¡œ ë³€í™˜
    - íƒ€ì„ìŠ¤í… ì •ê·œí™” (íŒ¨ë”© ë˜ëŠ” íŠ¸ë ì¼€ì´ì…˜)
    - íŠ¹ì§• ì •ê·œí™” (StandardScaler)
    - í…ì„œ ë³€í™˜
    """
    
    def __init__(
        self,
        target_timesteps: int = 87,
        n_channels: int = 8,
        scaler: StandardScaler = None,
        enable_dtw: bool = False
    ):
        """
        Args:
            target_timesteps: ëª©í‘œ íƒ€ì„ìŠ¤í… ê¸¸ì´ (ê¸°ë³¸: 87)
            n_channels: ì…ë ¥ ì±„ë„ ìˆ˜ (ê¸°ë³¸: 8)
            scaler: ì‚¬ì „ í•™ìŠµëœ StandardScaler (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
        """
        self.target_timesteps = target_timesteps
        self.n_channels = n_channels
        self.scaler = scaler if scaler is not None else StandardScaler()
        self.enable_dtw = enable_dtw
    
    def normalize_timesteps(self, data: np.ndarray) -> np.ndarray:
        """
        íƒ€ì„ìŠ¤í… ê¸¸ì´ ì •ê·œí™”
        
        Args:
            data: ì…ë ¥ ë°ì´í„° (timesteps, channels)
        
        Returns:
            normalized: ì •ê·œí™”ëœ ë°ì´í„° (target_timesteps, channels)
        """
        if len(data) == 0:
            return np.zeros((self.target_timesteps, self.n_channels))
        
        current_length = len(data)
        
        if current_length == self.target_timesteps:
            return data
        elif current_length > self.target_timesteps:
            # íŠ¸ë ì¼€ì´ì…˜ ëŒ€ì‹  ì˜µì…˜ì— ë”°ë¼ ê· ë“± ìƒ˜í”Œë§(DTW ëŒ€ì²´ ì ‘ê·¼)
            if self.enable_dtw:
                indices = np.linspace(0, current_length - 1, self.target_timesteps, dtype=int)
                return data[indices]
            else:
                # ê¸°ë³¸: ë‹¨ìˆœ íŠ¸ë ì¼€ì´ì…˜
                return data[:self.target_timesteps]
        else:
            # íŒ¨ë”©
            padding_length = self.target_timesteps - current_length
            padded_data = np.pad(
                data,
                ((0, padding_length), (0, 0)),
                mode='constant',
                constant_values=0.0
            )
            return padded_data
    
    def normalize_features(self, data: np.ndarray, fit: bool = False) -> np.ndarray:
        """
        íŠ¹ì§• ì •ê·œí™” (StandardScaler)
        
        Args:
            data: ì…ë ¥ ë°ì´í„° (timesteps, channels) ë˜ëŠ” (samples, timesteps, channels)
            fit: Trueì´ë©´ scalerë¥¼ í•™ìŠµ, Falseì´ë©´ ê¸°ì¡´ scaler ì‚¬ìš©
        
        Returns:
            normalized: ì •ê·œí™”ëœ ë°ì´í„°
        """
        original_shape = data.shape
        
        # 2Dë¡œ reshape
        if len(original_shape) == 2:
            data_reshaped = data
        else:
            data_reshaped = data.reshape(-1, original_shape[-1])
        
        # ì •ê·œí™”
        if fit:
            normalized = self.scaler.fit_transform(data_reshaped)
        else:
            normalized = self.scaler.transform(data_reshaped)
        
        # ì›ë˜ shapeìœ¼ë¡œ ë³µì›
        normalized = normalized.reshape(original_shape)
        
        return normalized
    
    def preprocess_single(
        self,
        raw_data: Union[np.ndarray, List[List[float]]],
        normalize: bool = True
    ) -> torch.Tensor:
        """
        ë‹¨ì¼ ìƒ˜í”Œ ì „ì²˜ë¦¬
        
        Args:
            raw_data: ì›ì‹œ ì„¼ì„œ ë°ì´í„° (timesteps, channels) ë˜ëŠ” List
            normalize: íŠ¹ì§• ì •ê·œí™” ì—¬ë¶€
        
        Returns:
            tensor: ì „ì²˜ë¦¬ëœ í…ì„œ (1, target_timesteps, channels)
        """
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        if isinstance(raw_data, list):
            raw_data = np.array(raw_data)
        
        # íƒ€ì„ìŠ¤í… ì •ê·œí™”
        normalized_data = self.normalize_timesteps(raw_data)
        
        # íŠ¹ì§• ì •ê·œí™”
        if normalize:
            normalized_data = self.normalize_features(normalized_data)
        
        # í…ì„œ ë³€í™˜ ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        tensor = torch.from_numpy(normalized_data).float().unsqueeze(0)
        
        return tensor
    
    def preprocess_batch(
        self,
        raw_data_list: List[Union[np.ndarray, List[List[float]]]],
        normalize: bool = True
    ) -> torch.Tensor:
        """
        ë°°ì¹˜ ì „ì²˜ë¦¬
        
        Args:
            raw_data_list: ì›ì‹œ ì„¼ì„œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            normalize: íŠ¹ì§• ì •ê·œí™” ì—¬ë¶€
        
        Returns:
            tensor: ì „ì²˜ë¦¬ëœ í…ì„œ (batch_size, target_timesteps, channels)
        """
        batch_data = []
        
        for raw_data in raw_data_list:
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            if isinstance(raw_data, list):
                raw_data = np.array(raw_data)
            
            # íƒ€ì„ìŠ¤í… ì •ê·œí™”
            normalized_data = self.normalize_timesteps(raw_data)
            batch_data.append(normalized_data)
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        batch_array = np.array(batch_data)
        
        # íŠ¹ì§• ì •ê·œí™”
        if normalize:
            batch_array = self.normalize_features(batch_array)
        
        # í…ì„œ ë³€í™˜
        tensor = torch.from_numpy(batch_array).float()
        
        return tensor
    
    def save_scaler(self, filepath: str):
        """
        Scaler ì €ì¥
        
        Args:
            filepath: ì €ì¥ ê²½ë¡œ (.pkl)
        """
        import pickle
        with open(filepath, 'wb') as f:
            pickle.dump(self.scaler, f)
    
    @classmethod
    def load_scaler(cls, filepath: str, **kwargs):
        """
        Scaler ë¡œë“œ
        
        Args:
            filepath: ë¡œë“œ ê²½ë¡œ (.pkl)
            **kwargs: InferencePreprocessor ì´ˆê¸°í™” ì¸ì
        
        Returns:
            preprocessor: Scalerê°€ ë¡œë“œëœ ì „ì²˜ë¦¬ê¸°
        """
        import pickle
        with open(filepath, 'rb') as f:
            scaler = pickle.load(f)
        
        return cls(scaler=scaler, **kwargs)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸ§ª InferencePreprocessor í…ŒìŠ¤íŠ¸...")
    
    # ì „ì²˜ë¦¬ê¸° ìƒì„±
    preprocessor = InferencePreprocessor(
        target_timesteps=87,
        n_channels=8
    )
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ê°€ë³€ ê¸¸ì´)
    raw_data_short = np.random.randn(50, 8)  # ì§§ì€ ì‹œí€€ìŠ¤
    raw_data_long = np.random.randn(100, 8)  # ê¸´ ì‹œí€€ìŠ¤
    
    # ë‹¨ì¼ ìƒ˜í”Œ ì „ì²˜ë¦¬
    print("\nğŸ“Š ë‹¨ì¼ ìƒ˜í”Œ ì „ì²˜ë¦¬:")
    tensor_short = preprocessor.preprocess_single(raw_data_short, normalize=False)
    print(f"  ì§§ì€ ì‹œí€€ìŠ¤ (50) â†’ {tensor_short.shape}")
    
    tensor_long = preprocessor.preprocess_single(raw_data_long, normalize=False)
    print(f"  ê¸´ ì‹œí€€ìŠ¤ (100) â†’ {tensor_long.shape}")
    
    # ë°°ì¹˜ ì „ì²˜ë¦¬
    print("\nğŸ“Š ë°°ì¹˜ ì „ì²˜ë¦¬:")
    raw_data_list = [raw_data_short, raw_data_long]
    batch_tensor = preprocessor.preprocess_batch(raw_data_list, normalize=False)
    print(f"  ë°°ì¹˜ shape: {batch_tensor.shape}")
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

