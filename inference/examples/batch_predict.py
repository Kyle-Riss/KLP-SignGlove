"""
ë°°ì¹˜ ì˜ˆì¸¡ ì˜ˆì œ

í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ìƒ˜í”Œì— ëŒ€í•œ ë°°ì¹˜ ì˜ˆì¸¡ ìˆ˜í–‰
"""

import sys
import numpy as np
from pathlib import Path

# inference ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent))

from inference import SignGloveInference


def example_batch_prediction():
    """ë°°ì¹˜ ì˜ˆì¸¡ ì˜ˆì œ"""
    print("=" * 60)
    print("ğŸ¯ ë°°ì¹˜ ì˜ˆì¸¡ ì˜ˆì œ")
    print("=" * 60)
    
    # 1. ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”
    print("\n1ï¸âƒ£ ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”...")
    model_path = "best_model/best_model.ckpt"
    
    try:
        engine = SignGloveInference(
            model_path=model_path,
            model_type='MSCSGRU',
            input_size=8,
            hidden_size=64,
            classes=24,
            cnn_filters=32,
            target_timesteps=87,
            device='cpu'
        )
    except FileNotFoundError:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
    
    # 2. ë°°ì¹˜ ë°ì´í„° ìƒì„±
    print("\n2ï¸âƒ£ ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„...")
    batch_size = 5
    raw_data_list = [np.random.randn(87, 8) for _ in range(batch_size)]
    print(f"   ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"   ê° ìƒ˜í”Œ shape: {raw_data_list[0].shape}")
    
    # 3. ë°°ì¹˜ ì˜ˆì¸¡
    print("\n3ï¸âƒ£ ë°°ì¹˜ ì˜ˆì¸¡ ì‹¤í–‰...")
    results = engine.predict_batch(raw_data_list, top_k=3)
    
    # 4. ê²°ê³¼ ì¶œë ¥
    print("\n4ï¸âƒ£ ì˜ˆì¸¡ ê²°ê³¼:")
    for i, result in enumerate(results, 1):
        print(f"\nğŸ“Š ìƒ˜í”Œ {i}:")
        print(f"  ì˜ˆì¸¡: {result['predicted_class']}")
        print(f"  í™•ë¥ : {result['confidence']:.4f}")
        print(f"  ìƒìœ„ 3ê°œ:")
        for j, pred in enumerate(result['top_k_predictions'][:3], 1):
            print(f"    {j}. {pred['class']}: {pred['confidence']:.4f}")


def example_variable_length_batch():
    """ê°€ë³€ ê¸¸ì´ ë°°ì¹˜ ì˜ˆì¸¡ ì˜ˆì œ"""
    print("\n" + "=" * 60)
    print("ğŸ¯ ê°€ë³€ ê¸¸ì´ ë°°ì¹˜ ì˜ˆì¸¡ ì˜ˆì œ")
    print("=" * 60)
    
    print("\në°°ì¹˜ ë‚´ ìƒ˜í”Œë“¤ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print("ìë™ìœ¼ë¡œ ëª¨ë“  ìƒ˜í”Œì´ ë™ì¼í•œ ê¸¸ì´(87)ë¡œ ì¡°ì •ë©ë‹ˆë‹¤.")
    
    print("""
    # ê°€ë³€ ê¸¸ì´ ë°°ì¹˜ ë°ì´í„°
    raw_data_list = [
        np.random.randn(50, 8),   # ì§§ì€ ìƒ˜í”Œ
        np.random.randn(87, 8),   # ì •í™•í•œ ê¸¸ì´
        np.random.randn(100, 8),  # ê¸´ ìƒ˜í”Œ
        np.random.randn(70, 8),   # ì¤‘ê°„ ê¸¸ì´
    ]
    
    # ë°°ì¹˜ ì˜ˆì¸¡ (ìë™ìœ¼ë¡œ ê¸¸ì´ ì¡°ì •)
    results = engine.predict_batch(raw_data_list)
    """)


def example_large_batch():
    """ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì œ"""
    print("\n" + "=" * 60)
    print("ğŸ¯ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì œ")
    print("=" * 60)
    
    print("\nëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤:")
    print("""
    def predict_large_batch(engine, raw_data_list, chunk_size=32):
        '''ëŒ€ìš©ëŸ‰ ë°°ì¹˜ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬'''
        all_results = []
        
        for i in range(0, len(raw_data_list), chunk_size):
            chunk = raw_data_list[i:i + chunk_size]
            results = engine.predict_batch(chunk)
            all_results.extend(results)
            
            print(f'ì²˜ë¦¬ ì™„ë£Œ: {len(all_results)}/{len(raw_data_list)}')
        
        return all_results
    
    # ì‚¬ìš© ì˜ˆì œ
    large_data_list = [np.random.randn(87, 8) for _ in range(1000)]
    results = predict_large_batch(engine, large_data_list, chunk_size=32)
    """)


def example_batch_statistics():
    """ë°°ì¹˜ ì˜ˆì¸¡ í†µê³„ ì˜ˆì œ"""
    print("\n" + "=" * 60)
    print("ğŸ¯ ë°°ì¹˜ ì˜ˆì¸¡ í†µê³„ ì˜ˆì œ")
    print("=" * 60)
    
    print("\në°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼ì˜ í†µê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print("""
    # ë°°ì¹˜ ì˜ˆì¸¡
    results = engine.predict_batch(raw_data_list)
    
    # í†µê³„ ê³„ì‚°
    predicted_classes = [r['predicted_class'] for r in results]
    confidences = [r['confidence'] for r in results]
    
    # í´ë˜ìŠ¤ë³„ ë¹ˆë„
    from collections import Counter
    class_counts = Counter(predicted_classes)
    
    print('í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¹ˆë„:')
    for class_name, count in class_counts.most_common():
        print(f'  {class_name}: {count}ê°œ')
    
    # í‰ê·  í™•ë¥ 
    avg_confidence = np.mean(confidences)
    print(f'\\ní‰ê·  í™•ë¥ : {avg_confidence:.4f}')
    
    # ì €ì‹ ë¢°ë„ ìƒ˜í”Œ
    low_conf_samples = [i for i, c in enumerate(confidences) if c < 0.5]
    print(f'ì €ì‹ ë¢°ë„ ìƒ˜í”Œ ({len(low_conf_samples)}ê°œ): {low_conf_samples}')
    """)


if __name__ == "__main__":
    # ë°°ì¹˜ ì˜ˆì¸¡ ì˜ˆì œ
    example_batch_prediction()
    
    # ê°€ë³€ ê¸¸ì´ ë°°ì¹˜ ì˜ˆì œ
    example_variable_length_batch()
    
    # ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì˜ˆì œ
    example_large_batch()
    
    # ë°°ì¹˜ í†µê³„ ì˜ˆì œ
    example_batch_statistics()
    
    print("\n" + "=" * 60)
    print("âœ… ì˜ˆì œ ì‹¤í–‰ ì™„ë£Œ!")
    print("=" * 60)




