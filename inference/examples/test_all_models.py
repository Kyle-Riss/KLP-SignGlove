#!/usr/bin/env python3
"""
4ê°œ ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸: GRU, StackedGRU, MS3DGRU, MS3DStackedGRU
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

import numpy as np
import time
from inference import SignGloveInference


def test_all_models():
    """4ê°œ ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
    
    print("=" * 80)
    print("ğŸš€ 4ê°œ ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸: GRU, StackedGRU, MS3DGRU, MS3DStackedGRU")
    print("=" * 80)
    print()
    
    # ëª¨ë¸ ì„¤ì • (ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œëŠ” ì‹¤ì œ ê²½ë¡œë¡œ í™•ì¸ í•„ìš”)
    models_config = {
        'GRU': {
            'path': 'archive/checkpoints_backup/checkpoints_backup/GRU_best.ckpt',
            'type': 'GRU',
            'hidden_size': 64,
            'dropout': 0.2,
            'expected_acc': '98.36%'
        },
        'StackedGRU': {
            'path': 'archive/checkpoints_backup/checkpoints_backup/GRU_best.ckpt',  # StackedGRU ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìœ¼ë©´ GRU ì‚¬ìš©
            'type': 'StackedGRU',
            'hidden_size': 64,
            'dropout': 0.2,
            'expected_acc': '95.43%'
        },
        'MS3DGRU': {
            'path': 'best_model/ms3dgru_best.ckpt',
            'type': 'MS3DGRU',
            'cnn_filters': 32,
            'dropout': 0.1,
            'expected_acc': '98.40%'
        },
        'MS3DStackedGRU': {
            'path': 'best_model/ms3dgru_best.ckpt',  # MS3DStackedGRU ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìœ¼ë©´ MS3DGRU ì‚¬ìš©
            'type': 'MS3DStackedGRU',
            'cnn_filters': 32,
            'dropout': 0.05,
            'expected_acc': '98.24%'
        }
    }
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±...")
    test_data = np.random.randn(87, 8)  # (timesteps, 8 channels)
    batch_data = [np.random.randn(87, 8) for _ in range(3)]
    print(f"  ë‹¨ì¼ ìƒ˜í”Œ shape: {test_data.shape}")
    print(f"  ë°°ì¹˜ í¬ê¸°: {len(batch_data)}")
    print()
    
    results = {}
    
    # ê° ëª¨ë¸ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
    for model_name, config in models_config.items():
        print("=" * 80)
        print(f"ğŸ¤– ëª¨ë¸: {model_name}")
        print(f"  ì˜ˆìƒ ì„±ëŠ¥: {config['expected_acc']}")
        print("-" * 80)
        
        try:
            # ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”
            init_params = {
                'model_path': config['path'],
                'model_type': config['type'],
                'input_size': 8,
                'hidden_size': config.get('hidden_size', 64),
                'classes': 24,
                'device': 'cpu',
                'dropout': config['dropout']
            }
            
            if 'cnn_filters' in config:
                init_params['cnn_filters'] = config['cnn_filters']
            
            print(f"  ì´ˆê¸°í™” ì¤‘...")
            engine = SignGloveInference(**init_params)
            
            # ëª¨ë¸ ì •ë³´
            info = engine.get_model_info()
            print(f"  âœ… ì´ˆê¸°í™” ì™„ë£Œ!")
            print(f"     - íŒŒë¼ë¯¸í„° ìˆ˜: {info.get('total_parameters', 'N/A'):,}")
            print(f"     - ë””ë°”ì´ìŠ¤: {info['device']}")
            print()
            
            # 1. ë‹¨ì¼ ìƒ˜í”Œ ì˜ˆì¸¡
            print(f"  ğŸ“Œ ë‹¨ì¼ ìƒ˜í”Œ ì˜ˆì¸¡:")
            start_time = time.time()
            result = engine.predict_single(test_data)
            inference_time = (time.time() - start_time) * 1000
            
            print(f"     ì˜ˆì¸¡ í´ë˜ìŠ¤: {result['predicted_class']}")
            print(f"     í™•ë¥ : {result['confidence']:.4f}")
            print(f"     ì¶”ë¡  ì‹œê°„: {inference_time:.2f}ms")
            print(f"     ìƒìœ„ 3ê°œ: {[p['class'] for p in result['top_k_predictions'][:3]]}")
            print()
            
            # 2. ë°°ì¹˜ ì˜ˆì¸¡
            print(f"  ğŸ“¦ ë°°ì¹˜ ì˜ˆì¸¡ (3ê°œ ìƒ˜í”Œ):")
            start_time = time.time()
            batch_results = engine.predict_batch(batch_data)
            batch_time = (time.time() - start_time) * 1000
            
            for i, res in enumerate(batch_results, 1):
                print(f"     ìƒ˜í”Œ {i}: {res['predicted_class']} (í™•ë¥ : {res['confidence']:.4f})")
            print(f"     ë°°ì¹˜ ì¶”ë¡  ì‹œê°„: {batch_time:.2f}ms (ìƒ˜í”Œë‹¹ {batch_time/len(batch_data):.2f}ms)")
            print()
            
            # 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
            print(f"  âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (100íšŒ ë°˜ë³µ):")
            n_iterations = 100
            start_time = time.time()
            for _ in range(n_iterations):
                _ = engine.predict_single(test_data, return_all_info=False)
            avg_time = ((time.time() - start_time) / n_iterations) * 1000
            
            print(f"     í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.2f}ms")
            print(f"     ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰: {1000/avg_time:.1f} samples/sec")
            print()
            
            results[model_name] = {
                'success': True,
                'single_time': inference_time,
                'batch_time': batch_time,
                'avg_time': avg_time,
                'throughput': 1000/avg_time,
                'predicted_class': result['predicted_class'],
                'confidence': result['confidence']
            }
            
        except FileNotFoundError as e:
            print(f"  âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config['path']}")
            print(f"     ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.")
            results[model_name] = {'success': False, 'error': 'FileNotFound'}
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            results[model_name] = {'success': False, 'error': str(e)}
        
        print()
    
    # ê²°ê³¼ ìš”ì•½
    print("=" * 80)
    print("ğŸ“Š ì¶”ë¡  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print()
    print(f"{'ëª¨ë¸':<20} {'ìƒíƒœ':<10} {'í‰ê·  ì‹œê°„(ms)':<15} {'ì²˜ë¦¬ëŸ‰(/sec)':<15} {'ì˜ˆì¸¡ í´ë˜ìŠ¤':<10}")
    print("-" * 80)
    
    for model_name, result in results.items():
        if result['success']:
            print(f"{model_name:<20} {'âœ… ì„±ê³µ':<10} {result['avg_time']:<15.2f} "
                  f"{result['throughput']:<15.1f} {result['predicted_class']:<10}")
        else:
            print(f"{model_name:<20} {'âŒ ì‹¤íŒ¨':<10} {'-':<15} {'-':<15} {'-':<10}")
    
    print()
    print("=" * 80)
    print("âœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    test_all_models()

