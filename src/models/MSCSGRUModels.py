import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple
from torch import Tensor


class MSCGRU(nn.Module):
    """
    MS-CGRU: Multi-Scale CNN + Single GRU ëª¨ë¸
    Stacked GRU ëŒ€ì‹  ë‹¨ì¼ GRU ì‚¬ìš©
    """
    
    def __init__(
        self,
        learning_rate,
        input_size=8,
        hidden_size=64,
        classes=34,
        cnn_filters=32,
        dropout=0.3,
        **kwargs
    ):
        super().__init__()
        
        self.lr = learning_rate
        self.classes = classes
        
        # Multi-Scale CNN: 3ê°œ íƒ€ì›Œ ë³‘ë ¬ ì²˜ë¦¬
        self.tower1 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 3, padding=1),
            nn.BatchNorm1d(cnn_filters), nn.ReLU()
        )
        self.tower2 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 5, padding=2),
            nn.BatchNorm1d(cnn_filters), nn.ReLU()
        )
        self.tower3 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 7, padding=3),
            nn.BatchNorm1d(cnn_filters), nn.ReLU()
        )
        
        # CNN í›„ì²˜ë¦¬
        self.cnn_post = nn.Sequential(
            nn.BatchNorm1d(cnn_filters * 3),
            nn.ReLU(),
            nn.MaxPool1d(2, 2),
            nn.Dropout(dropout)
        )
        
        # Single GRU
        self.gru = nn.GRU(cnn_filters * 3, hidden_size, 1, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        
        # ë¶„ë¥˜ê¸°
        self.output_layers = nn.Sequential(
            nn.Linear(hidden_size, 2*hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(2*hidden_size, classes)
        )
    
    def forward(self, x: Tensor, x_mask: Tensor, y_targets: Tensor) -> Tuple[Tensor, Tensor]:
        # Multi-Scale CNN
        x_conv = x.transpose(1, 2)  # (batch, channels, time)
        t1 = self.tower1(x_conv)
        t2 = self.tower2(x_conv) 
        t3 = self.tower3(x_conv)
        conv_out = torch.cat([t1, t2, t3], dim=1)
        conv_out = self.cnn_post(conv_out)
        
        # Single GRU
        conv_out = conv_out.transpose(1, 2)  # (batch, time, channels)
        gru_out, _ = self.gru(conv_out)
        final_features = gru_out[:, -1, :]  # ë§ˆì§€ë§‰ ì‹œê°„ ë‹¨ê³„
        final_features = self.dropout(final_features)
        
        # ë¶„ë¥˜
        logits = self.output_layers(final_features)
        loss = F.cross_entropy(logits, y_targets)
        
        return logits, loss


class CNNGRU(nn.Module):
    """
    CNN-GRU: ë‹¨ì¼ ìŠ¤ì¼€ì¼ CNN + GRU ëª¨ë¸
    ë©€í‹°ìŠ¤ì¼€ì¼ ëŒ€ì‹  ë‹¨ì¼ CNN ì‚¬ìš©
    """
    
    def __init__(
        self,
        learning_rate,
        input_size=8,
        hidden_size=64,
        classes=34,
        cnn_filters=32,
        dropout=0.3,
        **kwargs
    ):
        super().__init__()
        
        self.lr = learning_rate
        self.classes = classes
        
        # ë‹¨ì¼ CNN
        self.cnn = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 3, padding=1),
            nn.BatchNorm1d(cnn_filters),
            nn.ReLU(),
            nn.MaxPool1d(2, 2),
            nn.Dropout(dropout)
        )
        
        # GRU
        self.gru = nn.GRU(cnn_filters, hidden_size, 1, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        
        # ë¶„ë¥˜ê¸°
        self.output_layers = nn.Sequential(
            nn.Linear(hidden_size, 2*hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(2*hidden_size, classes)
        )
    
    def forward(self, x: Tensor, x_mask: Tensor, y_targets: Tensor) -> Tuple[Tensor, Tensor]:
        # CNN
        x_conv = x.transpose(1, 2)  # (batch, channels, time)
        conv_out = self.cnn(x_conv)
        
        # GRU
        conv_out = conv_out.transpose(1, 2)  # (batch, time, channels)
        gru_out, _ = self.gru(conv_out)
        final_features = gru_out[:, -1, :]  # ë§ˆì§€ë§‰ ì‹œê°„ ë‹¨ê³„
        final_features = self.dropout(final_features)
        
        # ë¶„ë¥˜
        logits = self.output_layers(final_features)
        loss = F.cross_entropy(logits, y_targets)
        
        return logits, loss


class CNNStackedGRU(nn.Module):
    """
    CNN-StackedGRU: ë‹¨ì¼ ìŠ¤ì¼€ì¼ CNN + 2ì¸µ GRU ëª¨ë¸
    ë‹¨ì¼ Conv1D ë’¤ì— 2ê°œì˜ GRU ì¸µì„ ìˆœì°¨ë¡œ ë°°ì¹˜
    """
    
    def __init__(
        self,
        learning_rate,
        input_size=8,
        hidden_size=64,
        classes=34,
        cnn_filters=32,
        dropout=0.3,
        **kwargs
    ):
        super().__init__()
        
        self.lr = learning_rate
        self.classes = classes
        
        # ë‹¨ì¼ CNN
        self.cnn = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 3, padding=1),
            nn.BatchNorm1d(cnn_filters),
            nn.ReLU(),
            nn.MaxPool1d(2, 2),
            nn.Dropout(dropout)
        )
        
        # Stacked GRU (2ì¸µ)
        self.gru1 = nn.GRU(cnn_filters, hidden_size, 1, batch_first=True)
        self.gru2 = nn.GRU(hidden_size, hidden_size, 1, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        
        # ë¶„ë¥˜ê¸°
        self.output_layers = nn.Sequential(
            nn.Linear(hidden_size, 2*hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(2*hidden_size, classes)
        )
    
    def forward(self, x: Tensor, x_mask: Tensor, y_targets: Tensor) -> Tuple[Tensor, Tensor]:
        # CNN
        x_conv = x.transpose(1, 2)  # (batch, channels, time)
        conv_out = self.cnn(x_conv)
        
        # GRU 2ì¸µ
        conv_out = conv_out.transpose(1, 2)  # (batch, time, channels)
        gru1_out, _ = self.gru1(conv_out)
        gru1_out = self.dropout(gru1_out)
        gru2_out, _ = self.gru2(gru1_out)
        final_features = gru2_out[:, -1, :]  # ë§ˆì§€ë§‰ ì‹œê°„ ë‹¨ê³„
        final_features = self.dropout(final_features)
        
        # ë¶„ë¥˜
        logits = self.output_layers(final_features)
        loss = F.cross_entropy(logits, y_targets)
        
        return logits, loss


class MSCSGRU(nn.Module):
    """
    MS-CSGRU: Multi-Scale CNN + Stacked GRU ëª¨ë¸
    ASL GRU ìŠ¤íƒ€ì¼ë¡œ ê°„ê²°í•˜ê²Œ êµ¬í˜„
    """
    
    def __init__(
        self,
        learning_rate,
        input_size=8,
        hidden_size=64,
        classes=34,
        cnn_filters=32,
        gru_layers=2,
        dropout=0.3,
        **kwargs
    ):
        super().__init__()
        
        self.lr = learning_rate
        self.classes = classes
        
        # Multi-Scale CNN: 3ê°œ íƒ€ì›Œ ë³‘ë ¬ ì²˜ë¦¬
        self.tower1 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 3, padding=1),
            nn.BatchNorm1d(cnn_filters), nn.ReLU()
        )
        self.tower2 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 5, padding=2),
            nn.BatchNorm1d(cnn_filters), nn.ReLU()
        )
        self.tower3 = nn.Sequential(
            nn.Conv1d(input_size, cnn_filters, 7, padding=3),
            nn.BatchNorm1d(cnn_filters), nn.ReLU()
        )
        
        # CNN í›„ì²˜ë¦¬
        self.cnn_post = nn.Sequential(
            nn.BatchNorm1d(cnn_filters * 3),
            nn.ReLU(),
            nn.MaxPool1d(2, 2),
            nn.Dropout(dropout)
        )
        
        # Stacked GRU
        self.gru1 = nn.GRU(cnn_filters * 3, hidden_size, 1, batch_first=True)
        self.gru2 = nn.GRU(hidden_size, hidden_size, 1, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        
        # ë¶„ë¥˜ê¸°
        self.output_layers = nn.Sequential(
            nn.Linear(hidden_size, 2*hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(2*hidden_size, classes)
        )
    
    def forward(self, x: Tensor, x_mask: Tensor, y_targets: Tensor) -> Tuple[Tensor, Tensor]:
        # Multi-Scale CNN
        x_conv = x.transpose(1, 2)  # (batch, channels, time)
        t1 = self.tower1(x_conv)
        t2 = self.tower2(x_conv) 
        t3 = self.tower3(x_conv)
        conv_out = torch.cat([t1, t2, t3], dim=1)
        conv_out = self.cnn_post(conv_out)
        
        # Stacked GRU
        conv_out = conv_out.transpose(1, 2)  # (batch, time, channels)
        gru1_out, _ = self.gru1(conv_out)
        gru1_out = self.dropout(gru1_out)
        gru2_out, _ = self.gru2(gru1_out)
        final_features = gru2_out[:, -1, :]  # ë§ˆì§€ë§‰ ì‹œê°„ ë‹¨ê³„
        
        # ë¶„ë¥˜
        logits = self.output_layers(final_features)
        loss = F.cross_entropy(logits, y_targets)
        
        return logits, loss


# Test the model
if __name__ == "__main__":
    print("ğŸ§ª CNN-GRU, MS-CGRU & MS-CSGRU ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
    
    # Test data
    batch_size, time_steps, input_channels = 4, 87, 8
    num_classes = 34
    
    x = torch.randn(batch_size, time_steps, input_channels)
    x_mask = torch.ones(batch_size, time_steps)
    y_targets = torch.randint(0, num_classes, (batch_size,))
    
    # Test CNN-GRU (Single CNN + GRU)
    print("\nğŸ“Š CNN-GRU (Single CNN + GRU) í…ŒìŠ¤íŠ¸:")
    model_cnn_gru = CNNGRU(
        learning_rate=1e-3,
        input_size=input_channels,
        hidden_size=64,
        classes=num_classes
    )
    
    logits, loss = model_cnn_gru(x, x_mask, y_targets)
    print(f"ì¶œë ¥ shape: {logits.shape}")
    print(f"ì†ì‹¤: {loss.item():.4f}")
    
    # Test MS-CGRU (Multi-Scale CNN + Single GRU)
    print("\nğŸ“Š MS-CGRU (Multi-Scale CNN + Single GRU) í…ŒìŠ¤íŠ¸:")
    model_ms_cgru = MSCGRU(
        learning_rate=1e-3,
        input_size=input_channels,
        hidden_size=64,
        classes=num_classes
    )
    
    logits, loss = model_ms_cgru(x, x_mask, y_targets)
    print(f"ì¶œë ¥ shape: {logits.shape}")
    print(f"ì†ì‹¤: {loss.item():.4f}")
    
    # Test MS-CSGRU (Multi-Scale CNN + Stacked GRU)
    print("\nğŸ“Š MS-CSGRU (Multi-Scale CNN + Stacked GRU) í…ŒìŠ¤íŠ¸:")
    model_ms_csgru = MSCSGRU(
        learning_rate=1e-3,
        input_size=input_channels,
        hidden_size=64,
        classes=num_classes
    )
    
    logits, loss = model_ms_csgru(x, x_mask, y_targets)
    print(f"ì¶œë ¥ shape: {logits.shape}")
    print(f"ì†ì‹¤: {loss.item():.4f}")
    
    print("\nâœ… ëª¨ë“  ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")