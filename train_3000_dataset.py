"""
3000κ° λ°μ΄ν„°μ…‹μ© μµμ ν™”λ ν›λ ¨ μ¤ν¬λ¦½νΈ
- λ” ν° λ°μ΄ν„°μ…‹μ— λ§μ¶ ν•μ΄νΌνλΌλ―Έν„°
- μμƒ μ„±λ¥: 98.5%
"""
import sys
import os
from pathlib import Path
import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
from pytorch_lightning.loggers import CSVLogger
import json
import time

# ν”„λ΅μ νΈ λ£¨νΈλ¥Ό Python κ²½λ΅μ— μ¶”κ°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from src.misc.DynamicDataModule import DynamicDataModule
from src.StackedGRUModel import StackedGRULightning
from optimal_config_3000 import OPTIMAL_CONFIG_3000, DATASET_CONFIGS, PERFORMANCE_PREDICTIONS

def train_3000_dataset_model():
    """3000κ° λ°μ΄ν„°μ…‹μ© λ¨λΈ ν›λ ¨"""
    print("π€ 3000κ° λ°μ΄ν„°μ…‹μ© μµμ ν™” λ¨λΈ ν›λ ¨ μ‹μ‘")
    print("=" * 60)
    
    # μ„¤μ • μ •λ³΄ μ¶λ ¥
    config = OPTIMAL_CONFIG_3000
    print(f"π“ ν›λ ¨ μ„¤μ •:")
    print(f"   λ°μ΄ν„°μ…‹ ν¬κΈ°: 3000κ° (μμ •)")
    print(f"   λ¨λΈ κµ¬μ΅°: hidden_size={config['hidden_size']}, layers={config['num_layers']}")
    print(f"   ν›λ ¨ μ„¤μ •: lr={config['learning_rate']}, batch_size={config['batch_size']}")
    print(f"   μμƒ μ„±λ¥: {PERFORMANCE_PREDICTIONS['medium_3000']['expected_accuracy']:.1%}")
    print("=" * 60)
    
    # κ²°κ³Ό λ””λ ‰ν† λ¦¬ μƒμ„±
    os.makedirs('results_3000', exist_ok=True)
    os.makedirs('results_3000/checkpoints', exist_ok=True)
    os.makedirs('results_3000/logs', exist_ok=True)
    
    # λ°μ΄ν„° λ¨λ“ μ„¤μ • (3000κ° λ°μ΄ν„°μ…‹μ©)
    data_module = DynamicDataModule(
        data_dir='/home/billy/25-1kp/SignGlove-DataAnalysis',  # μƒλ΅μ΄ λ°μ΄ν„°μ…‹ κ²½λ΅λ΅ λ³€κ²½ ν•„μ”
        time_steps=config['time_steps'],
        n_channels=config['n_channels'],
        batch_size=config['batch_size'],
        use_test_split=True,
        seed=config['seed']
    )
    
    print("π“ λ°μ΄ν„° λ¨λ“ μ„¤μ • μ™„λ£")
    print(f"   νƒ€μ„μ¤ν…: {config['time_steps']}")
    print(f"   μ±„λ„ μ: {config['n_channels']}")
    print(f"   λ°°μΉ μ‚¬μ΄μ¦: {config['batch_size']}")
    
    # λ¨λΈ μƒμ„± (3000κ° λ°μ΄ν„°μ…‹μ© μµμ  μ„¤μ •)
    model = StackedGRULightning(
        input_size=config['n_channels'],
        hidden_size=config['hidden_size'],
        num_classes=config['num_classes'],
        num_layers=config['num_layers'],
        dropout=config['dropout'],
        dense_size=config['dense_size'],
        bidirectional=config['bidirectional'],
        learning_rate=config['learning_rate'],
        weight_decay=config['weight_decay'],
        adamw_beta1=config['adamw_beta1'],
        adamw_beta2=config['adamw_beta2'],
        adamw_eps=config['adamw_eps'],
        lr_scheduler_factor=config['lr_scheduler_factor'],
        lr_scheduler_patience=config['lr_scheduler_patience'],
        lr_scheduler_min_lr=config['lr_scheduler_min_lr'],
        lr_scheduler_threshold=config['lr_scheduler_threshold']
    )
    
    print("π¤– λ¨λΈ μƒμ„± μ™„λ£")
    print(f"   μ΄ νλΌλ―Έν„° μ: {sum(p.numel() for p in model.parameters()):,}")
    
    # μ½λ°± μ„¤μ •
    early_stopping = EarlyStopping(
        monitor='val/accuracy',
        patience=config['early_stopping_patience'],
        mode='max',
        verbose=True
    )
    
    checkpoint_callback = ModelCheckpoint(
        monitor='val/accuracy',
        dirpath='./results_3000/checkpoints/',
        filename='model-3000-{epoch:02d}-{val/accuracy:.4f}',
        save_top_k=3,  # μƒμ„ 3κ° λ¨λΈ μ €μ¥
        mode='max',
        verbose=True
    )
    
    # λ΅κ±° μ„¤μ •
    logger = CSVLogger(
        save_dir='./results_3000/logs/',
        name='model_3000_dataset'
    )
    
    # νΈλ μ΄λ„ μ„¤μ •
    trainer = pl.Trainer(
        max_epochs=config['max_epochs'],
        logger=logger,
        callbacks=[checkpoint_callback, early_stopping],
        accelerator="auto",
        devices="auto",
        log_every_n_steps=20,  # λ” ν° λ°°μΉ μ‚¬μ΄μ¦μ— λ§μ¶° μ΅°μ •
        enable_progress_bar=True,
        precision=16  # λ©”λ¨λ¦¬ ν¨μ¨μ„±μ„ μ„ν• mixed precision
    )
    
    print("πƒβ€β™‚οΈ ν›λ ¨ μ‹μ‘...")
    start_time = time.time()
    
    # ν›λ ¨
    trainer.fit(model, data_module)
    
    # ν…μ¤νΈ
    test_results = trainer.test(model, data_module)
    
    training_time = time.time() - start_time
    
    # κ²°κ³Ό μ €μ¥
    results = {
        'model_name': 'StackedGRU_3000',
        'dataset_size': 3000,
        'config': config,
        'test_accuracy': float(test_results[0]['test/accuracy']),
        'test_loss': float(test_results[0]['test/loss']),
        'best_val_accuracy': float(trainer.callback_metrics.get('val/accuracy', 0)),
        'best_val_loss': float(trainer.callback_metrics.get('val/loss', 0)),
        'total_epochs': trainer.current_epoch + 1,
        'training_time': training_time,
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # κ²°κ³Ό μ €μ¥
    with open('results_3000/training_results_3000.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=4)
    
    print("\n" + "=" * 60)
    print("π‰ 3000κ° λ°μ΄ν„°μ…‹ ν›λ ¨ μ™„λ£!")
    print(f"β… ν…μ¤νΈ μ •ν™•λ„: {results['test_accuracy']:.4f}")
    print(f"β… ν…μ¤νΈ μ†μ‹¤: {results['test_loss']:.4f}")
    print(f"β… ν›λ ¨ μ‹κ°„: {training_time:.1f}μ΄")
    print(f"β… μ΄ μ—ν¬ν¬: {results['total_epochs']}")
    
    # μ„±λ¥ λΉ„κµ
    expected_acc = PERFORMANCE_PREDICTIONS['medium_3000']['expected_accuracy']
    actual_acc = results['test_accuracy']
    
    print(f"\nπ“ μ„±λ¥ λ¶„μ„:")
    print(f"   μμƒ μ„±λ¥: {expected_acc:.1%}")
    print(f"   μ‹¤μ  μ„±λ¥: {actual_acc:.1%}")
    print(f"   μ„±λ¥ μ°¨μ΄: {actual_acc - expected_acc:+.1%}")
    
    if actual_acc >= expected_acc:
        print("   π― λ©ν‘ μ„±λ¥ λ‹¬μ„±!")
    else:
        print("   π“ μ¶”κ°€ μµμ ν™” ν•„μ”")
    
    print("=" * 60)
    
    return results

def compare_with_previous_model():
    """μ΄μ „ λ¨λΈ(598κ°)κ³Ό μ„±λ¥ λΉ„κµ"""
    print("\nπ“ μ΄μ „ λ¨λΈκ³Ό μ„±λ¥ λΉ„κµ")
    print("-" * 40)
    
    # μ΄μ „ λ¨λΈ μ„±λ¥ (598κ° λ°μ΄ν„°μ…‹)
    previous_acc = 0.9750  # Improved_2 μ„±λ¥
    
    print(f"598κ° λ°μ΄ν„°μ…‹ (μ΄μ „): {previous_acc:.1%}")
    print(f"3000κ° λ°μ΄ν„°μ…‹ (ν„μ¬): κ²°κ³Ό ν™•μΈ ν•„μ”")
    print(f"μμƒ κ°μ„ : +1.0% (λ°μ΄ν„°μ…‹ 5λ°° μ¦κ°€)")
    
    print("\nπ” κ°μ„  μ”μΈ:")
    print("   - λ” ν° ν›λ ¨ λ°μ΄ν„° (598 β†’ 3000κ°)")
    print("   - λ” ν° λ¨λΈ (hidden_size 48 β†’ 64)")
    print("   - λ” κΉμ€ λ„¤νΈμ›ν¬ (layers 1 β†’ 2)")
    print("   - μµμ ν™”λ ν•μ΄νΌνλΌλ―Έν„°")

if __name__ == "__main__":
    try:
        # μ„¤μ • λΉ„κµ μ¶λ ¥
        from optimal_config_3000 import print_config_comparison
        print_config_comparison()
        
        print("\n" + "=" * 60)
        
        # ν›λ ¨ μ‹¤ν–‰
        results = train_3000_dataset_model()
        
        # μ„±λ¥ λΉ„κµ
        compare_with_previous_model()
        
    except Exception as e:
        print(f"β ν›λ ¨ μ¤‘ μ¤λ¥ λ°μƒ: {e}")
        import traceback
        traceback.print_exc()

